{"pages":[{"title":"About Me","text":"&emsp;&emsp;Welcome! I am Mr·Zh, is a JAVA developer, passionate about open source technology. And I’ m also very willing to share technical experience. Wish you all have a good harvest in my blog garden. (￫ܫ￩) 《从PAXOS到ZOOKEEPER分布式一致性原理与实践》 《高性能MySQL第三版(超清晰中文)》 《垃圾回收算法手册 自动内存管理的艺术》 《企业IT架构转型之道 阿里巴巴中台战略思想与架构实战【高清+完整目录】》 《深入理解计算机系统（第三版)》 《深入理解Java虚拟机：JVM高级特性与最佳实践》 《数据结构与算法分析C++描述(第三版)》 《图灵程序设计丛书 算法 第4版》 《Computer Networking A Top-Down Approach 5th Edition》 《Data Structures and Algorithms in Python》 《Data.Structures And Algorithm Analysis in C++ 4e》 《Effective Python》 《Effective.Java.3rd.Edition.2018.1》 《HADOOP权威指南+第3版+完整版》 《how_tomcat_works》 《JAVA并发编程实战》 《Java核心技术 卷1 基础知识 原书第9版》 《python绝技：运用python成为顶级黑客》 《Redis实战》 《TCP IP Sockets in Java Practical Guide for Programmers,.2ed》 《The Garbage Collection Handbook》 《Tomcat深入剖析》 《Web Scraping with Python》 ✔️智能文章解析爬虫 基于行块分布函数的通用网页正文抽取算法智能解析正文，在此基础上，重写TAG清除模块，取消通过行块密度判断正文的方式，而是通过计算正文置信度分数来提高命中率 ✔️实时手势自动识别系统 基于 Temporal Relation Networks 算法的短时序检测的手语自动识别系统，并且为了降低对硬件的依赖，采取了前后端分离的思 想，前端采用目标检测算法 Yolo v2 实时上传图片帧，服务器端进行并发检测","link":"/about/index.html"}],"posts":[{"title":"AQS同步器","text":"&emsp;&emsp;在 java.util.concurrent (JUC) 并发包中，如 ReentrantLock，Semaphore，CountDownLatch 等并发类的同步控制都是基于 AbstractQueuedSynchronizer (简称 AQS) 这个同步器抽象类来实现的。在这里较为深入的讨论同步器抽象类的实现原理与应用。 AQS简介AbstractQueuedSynchronizer 内部维护着一个 FIFO 的 CLH 队列，队列中的每个 Node 代表着一个需要获取锁的线程 &emsp;&emsp;自旋锁：自旋锁是指当一个线程尝试获取某个锁时，如果该锁已被其他线程占用，就一直循环检测锁是否被释放，而不是立刻进入线程挂起或睡眠状态。 CLH 锁（Craig, Landin, and Hagersten locks）：基于链表的可扩展、高性能、公平的自旋锁，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋 MCS 锁：在当前结点自旋，但由前驱结点通知其结束自旋 AQS 采用的是一种变种的 CLH 队列锁：原始 CLH 是在前驱结点自旋，通过判断 pred.locked 来自旋，而 AQS 的 CLH 则是根据前驱结点的状态来控制阻塞，不会一直自旋。同时当前驱结点释放锁时会去唤醒该结点使其参与竞争锁。 AQS 的结点的定义如下： 12345678910111213static final class Node { volatile int waitStatus; volatile Node prev; volatile Node next; volatile Thread thread; // 指向 Condition 队列中的后继节点 Node nextWaiter;} Node 结点中分别有指向前驱，后继的结点，入队时的线程以及结点状态（Condition 队列本文不涉及）。结点状态会存在以下几种： CANCELLED：线程取消 SIGNAL：当前线程的后继线程被阻塞或者即将被阻塞，当前线程释放锁或者取消后需要唤醒后继线程 CONDITION：在等待 Condition ，也就是在 Condition 队列中 PROPAGATE：当头结点处于 PROPAGATE，需要唤醒后继线程，为了保证共享模式下唤醒机制正常 0：初始状态 基于上述 Node 的定义，AQS 基本属性如下： 12345678// 队列的头结点private transient volatile Node head;// 队列的尾节点private transient volatile Node tail;// 同步状态private volatile int state; APIAbstractQueuedSynchronizer 的提供的接口主要有两种类型 控制同步状态AbstractQueuedSynchronizer 并不实现同步接口，所有对同步状态的控制都交由子类同步组件控制。比如 tryAcquire 代表由子类控制当前线程是否能独占式获取同步状态成功 方法 说明 boolean tryAcquire(int arg) 独占式获取同步状态 boolean tryRelease(int arg) 独占式释放同步状态 int tryAcquireShared(int arg) 共享式获取同步状态 boolean tryReleaseShared(int arg) 共享式释放同步状态 boolean isHeldExclusively() 检测当前线程是否获取独占锁 而在多线程环境中对状态的操纵必须确保原子性，因此它还提供了对状态控制的三组 API： 方法 说明 int getState() 获取同步状态 void setState() 设置同步状态 boolean compareAndSetState(int expect, int update) 通过 CAS 设置同步状态 通过这三组 API，子类可以线程安全的控制同步状态（同时子类需要确保实现是非阻塞的） 模板方法模板方法封装了获取同步状态成功或失败后的在队列中的一系列操作，子类可以直接调用 方法 说明 void acquire(int arg) 独占式获取同步状态，该方法将会调用 tryAcquire 尝试获取同步状态。获取成功则返回，获取失败，线程进入同步队列等待。 void acquireInterruptibly(int arg) 响应中断版的 acquire boolean tryAcquireNanos(int arg,long nanos) 超时 + 响应中断版的 acquire void acquireShared(int arg) 共享式获取同步状态，同一时刻可能会有多个线程获得同步状态。比如读写锁的读锁就是就是调用这个方法获取同步状态的。 void acquireSharedInterruptibly(int arg) 响应中断版的 acquireShared boolean tryAcquireSharedNanos(int arg,long nanos) 超时 + 响应中断版的 acquireShared boolean release(int arg) 独占式释放同步状态 boolean releaseShared(int arg) 共享式释放同步状态 互斥锁acquire12345public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();} tryAcquire 方法代表尝试获取一次互斥锁，需要子类根据需求去实现（比如 ReentrantLock 实现了公平锁和非公平锁），通过布尔变量来标志获取状态： 123protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException();} 若获取失败，则通过 addWaiter 方法将当前线程添加至阻塞队列 1234567891011121314151617181920212223242526272829303132333435363738private Node addWaiter(Node mode) { // 将线程封装在Node节点中 Node node = new Node(Thread.currentThread(), mode); // CAS 尝试将该节点插在队列尾 // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } // 如果不成功则通过自旋的方式插到队尾，直到插入成功 enq(node); return node;}private Node enq(final Node node) { for (;;) { Node t = tail; // 设置头结点，初始情况下，头结点是一个空结点(这里不会直接返回，因此即使阻塞队列为空，当前节点仍然是插在空结点之后) if (t == null) { // Must initialize if (compareAndSetHead(new Node())) tail = head; // 插入该结点到队尾 } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } }} 插入完成后，则会调用 acquireQueued() 方法对该结点进行有限次自旋获取锁，并在到达边界条件后阻塞 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); // 如果该节点的前一节点为头节点，那么它将有资格参与竞争锁 // 如果获取锁成功，则将当前结点设为头结点 if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } // 判断线程需不需要阻塞，和 CLH 不同，线程并不总是参与竞争锁，而是仅当线程被唤醒时竞争锁 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); }}private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; // 如果前驱节点为 SIGNAL 状态，那么在释放锁时会唤醒后继结点 // 因此这种情况当前结点会阻塞自己 if (ws == Node.SIGNAL) return true; // 如果前驱节点为 CANCELLED 状态，那么从后向前找到第一个非取消状态的节点 // 并更新当前结点的前驱为该结点 if (ws &gt; 0) { do { node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { // 如果前驱节点为 0 或 PROPAGATE，那么设置前驱结点的状态为 SIGNAL（可以说这一步才是标志会将每一个节点阻塞的一步） compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false;}// LockSupport.park(this) 来挂起线程，然后就停在这里了，等待被唤醒// 返回的时候会先判断是否由线程中断造成的，如果由线程中断造成，在这里会接下去置中断标记// 而 lockInterruptibly 方法则是抛出异常private final boolean parkAndCheckInterrupt() { LockSupport.park(this); return Thread.interrupted();} 那么总结下 acquire 方法的逻辑： 尝试获取互斥锁，若获取成功则直接返回 若获取失败，则将当前线程添加到阻塞队列尾（CAS 操作插入，自旋直到插入成功为止） 自旋/阻塞获取锁 尝试获取互斥锁（前驱结点必须为头结点时，当前结点才有资格竞争锁），若获取成功则将当前结点设为头结点后退出 若前驱结点为 SIGNAL 状态，则阻塞当前结点（唤醒后继续循环 自旋/阻塞获取锁 ） 若前驱结点为 CANCELLED 状态，则更新前驱到非取消结点 若前驱结点为 0 或 PROPAGATE，则设置前驱结点状态为 SIGNAL 状态 release123456789101112public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; // h == null 的情况就是阻塞队列为空（前面说过，第一个线程持有锁时不会放到头结点中） // h.waitStatus = 0，那么其后的结点必定没有阻塞（前面也说过，因为该值是由后继结点来赋值的，然后仅当该结点状态为阻塞状态，后继结点才会将自己阻塞，即 CLH 特性，根据前驱结点状态来控制自己） if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false;} tryRelease 方法代表尝试释放一次互斥锁，需要子类根据需求去实现，通过布尔变量来标志获取状态： 123protected boolean tryRelease(int arg) { throw new UnsupportedOperationException();} 在释放锁成功后，会判断当前结点状态来唤醒后继结点，即当前结点状态为 SIGNAL 状态时会唤醒后继结点 12345678910111213141516171819202122if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h);private void unparkSuccessor(Node node) { int ws = node.waitStatus; if (ws &lt; 0) // 设置头结点状态为 0 compareAndSetWaitStatus(node, ws, 0); // 从队尾往前找，找到 waitStatus &lt;= 0 的所有节点中排在最前面的(&gt; 0 代表节点取消阻塞) Node s = node.next; if (s == null || s.waitStatus &gt; 0) { s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; } // 唤醒该节点，也就是头结点的下一个不为取消阻塞状态的节点 if (s != null) LockSupport.unpark(s.thread);} 那么总结下 release 方法的逻辑： 尝试释放一次互斥锁，若释放失败，则直接返回失败 释放成功后，唤醒一个后继结点 互斥锁案例通过以上的理解，可以实现一个简单的互斥锁 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class MutexLock implements Lock { private Sync sync; public MutexLock() { this.sync = new Sync(); } private static class Sync extends AbstractQueuedSynchronizer { public Sync() { setState(0); } @Override protected boolean tryAcquire(int acquire) { if(compareAndSetState(0, 1)){ setExclusiveOwnerThread(Thread.currentThread()); return true; } return false; } @Override protected boolean tryRelease(int release) { if(getState() == 0){ throw new IllegalMonitorStateException(); } setExclusiveOwnerThread(null); setState(0); return true; } } @Override public void lock() { sync.acquire(1); } @Override public void lockInterruptibly() throws InterruptedException { sync.acquireInterruptibly(1); } @Override public boolean tryLock() { return sync.tryAcquire(1); } @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException { return sync.tryAcquireNanos(1, unit.toNanos(time)); } @Override public void unlock() { sync.release(1); } @Override public Condition newCondition() { return null; }} 内部类 Sync 继承 AbstractQueuedSynchronizer，并重载 tryAcquire 和 tryRelease 方法 tryAcquire 通过 CAS 尝试获取一次同步状态（0 -&gt; 1），若获取成功则设置当前持有锁的线程为自己 tryRelease 判断同步状态是否为 1，若是则重置同步状态为 0，且设置当前获取锁的线程为 null，否则抛出异常（互斥锁的释放不会有并发） 我们可以写个简单的并发计数测试： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class Main { // 计数 private static int count; public static void main(String[] args) { final Mutex mutex = new Mutex(); ExecutorService executorService = new ThreadPoolExecutor( 3, 5, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(100), new ThreadPoolExecutor.DiscardOldestPolicy() ); count = 0; int threadCnt = 10; for (int i = 0; i &lt; threadCnt; i++){ executorService.execute(new Runnable() { @Override public void run() { for(int i = 0; i &lt; 10000; i++){ mutex.lock(); try { count++; }finally { mutex.unlock(); } } } }); } executorService.shutdown(); try { executorService.awaitTermination(1, TimeUnit.DAYS); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"assert \" + threadCnt * 10000 + \" = \" + count + \" is true\"); }} 正常输出为： 1assert 100000 = 100000 is true 共享锁acquireShared1234public final void acquireShared(int arg) { if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);} tryAcquireShared 方法尝试获取一次共享锁，需要子类根据需求去实现。但和互斥锁不同的是，它以整型作为状态标志，负数代表获取失败，非负数代表获取成功，0 代表成功但之后的竞争线程不会成功 123protected int tryAcquireShared(int arg) { throw new UnsupportedOperationException();} 在获取共享锁失败时，会调用 doAcquireShared 将当前线程添加至阻塞队列并自旋获取共享锁 123456789101112131415161718192021222324252627282930313233private void doAcquireShared(int arg) { // 将当前线程添加至阻塞队列 final Node node = addWaiter(Node.SHARED); boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); // 如果该节点的前一节点为头节点，那么它将有资格参与竞争锁 // 如果获取锁成功，则将当前结点设为头结点 if (p == head) { int r = tryAcquireShared(arg); if (r &gt;= 0) { // 和互斥锁不同的点，共享锁会在获取锁成功后唤醒后继结点 setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; } } // 判断线程需不需要阻塞 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); }} 它的大体逻辑和互斥锁的自旋获取锁逻辑相同，但是它们之间有个很重要的不同点，即共享锁在获取锁成功后调用 setHeadAndPropagate 来唤醒后继结点 1234567891011121314151617181920212223242526272829303132333435private void setHeadAndPropagate(Node node, int propagate) { Node h = head; // Record old head for check below // 设为头结点 setHead(node); // 唤醒后继结点 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0) { Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); }}private void doReleaseShared() { for (;;) { Node h = head; if (h != null &amp;&amp; h != tail) { int ws = h.waitStatus; // 如果头结点处于 SIGNAL 状态，唤醒后继结点 if (ws == Node.SIGNAL) { if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); } // 如果头结点处于 0 的状态，设置头结点状态为 PROPAGATE // 这是为了解决共享锁的并发唤醒后继结点导致极端情况下存在线程永远无法唤醒的情况 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS } if (h == head) // loop if head changed break; }} 在判断是否需要唤醒后继结点这步，它的判断逻辑是 propagate &gt; 0 || h.waitStatus &lt; 0： propagate &gt; 0 ：tryAcquireShared 方法的返回值，代表当前线程获取共享锁成功（按理说 propagate = 0 的情况也属于获取锁成功，为什么不加进去呢？这是因为当 propagate = 0 时代表当前已经没有共享资源了，所以唤醒也没有意义了） h.waitStatus &lt; 0 ：头结点状态为 SIGNAL 或 PROPAGATE 时 &emsp;&emsp;在共享锁中会存在 PROPAGATE 状态： 获取共享锁成功后，如果头结点状态为 0（unparkSuccessor 时会将头结点状态设为0），会将头结点状态设为 PROPAGATE 123else if (ws == 0 &amp;&amp;​ !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))​ continue; // loop on failed CAS 判断后继结点是否需要唤醒时会判断头结点的状态 propagate &gt; 0 || h.waitStatus &lt; 0 之所以需要这个状态是因为共享锁的 唤醒后继结点 操作是并发操作，同时 propagate = 0 的情况不会唤醒后继结点，因此在一些极端情况下会存在阻塞结点无法被唤醒的情况 那么我们总结下获取共享锁的逻辑： 尝试获取共享锁，若获取成功则直接返回 若获取失败，则将当前线程添加到阻塞队列尾（CAS 操作插入，自旋直到插入成功为止） 自旋/阻塞获取锁 尝试获取共享锁（前驱结点必须为头结点时，当前结点才有资格竞争锁），若获取成功则尝试唤醒一个后继结点（唤醒的结点如果获取锁成功又会继续唤醒接下去的结点） 前驱结点为 SIGNAL 状态，则阻塞当前结点（唤醒后继续循环 自旋/阻塞获取锁 ） 前驱结点为 CANCELLED 状态，则更新前驱到非取消结点 前驱结点为 0 或 PROPAGATE，则设置前驱结点状态为 SIGNAL 状态 releaseShared1234567public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { doReleaseShared(); return true; } return false;} tryReleaseShared 方法代表尝试释放一次共享锁，需要子类根据需求去实现，通过布尔变量来标志获取状态： 123protected boolean tryReleaseShared(int arg) { throw new UnsupportedOperationException();} 释放成功后会调用 doReleaseShared 尝试唤醒一个后继结点，上面已经解释了。 共享锁案例基于以上分析，我们也可以实现一个同时允许 N 个线程进入的共享锁 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public class ShareLock implements Lock { private Sync sync; public ShareLock(Integer permit) { this.sync = new Sync(permit); } private static class Sync extends AbstractQueuedSynchronizer{ Sync(int permit){ setState(permit); } @Override protected int tryAcquireShared(int acquire) { for(;;){ int expect = getState(); int update = expect - acquire; if(update &lt; 0 || compareAndSetState(expect, update)){ return update; } } } @Override protected boolean tryReleaseShared(int release) { for(;;){ int expect = getState(); int update = expect + release; if(compareAndSetState(expect, update)){ return true; } } } } @Override public void lock() { sync.acquireShared(1); } @Override public void lockInterruptibly() throws InterruptedException { sync.acquireSharedInterruptibly(1); } @Override public boolean tryLock() { return sync.tryAcquireShared(1) &gt;= 0; } @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException { return sync.tryAcquireSharedNanos(1, unit.toNanos(time)); } @Override public void unlock() { sync.releaseShared(1); } @Override public Condition newCondition() { return null; }} 接下来对共享锁进行简单的测试： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class Main{ public static void main(String[] args) { final ShareLock shareLock = new ShareLock(2); ExecutorService executorService = new ThreadPoolExecutor( 5, 5, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(100), new ThreadPoolExecutor.DiscardOldestPolicy() ); int threadCnt = 10; for (int i = 0; i &lt; threadCnt; i++){ executorService.execute(new Runnable() { @Override public void run() { shareLock.lock(); try { System.out.println(Thread.currentThread().getName() + \": is running\"); Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } finally { shareLock.unlock(); } } }); } executorService.shutdown(); try { executorService.awaitTermination(1, TimeUnit.DAYS); } catch (InterruptedException e) { e.printStackTrace(); } }} 测试程序创建了一个允许最多两个线程同时进入的共享锁。因此正常情况下，日志会成双打印。 中断 thread.interrupt()：中断线程，将会设置该线程的中断状态位，即设置为 true（不会中断一个正在运行的线程，而是中断阻塞的线程） thread.interrupted()：判断某个线程是否已被发送过中断请求，该方法调用后会将中断标示位清除，即重新设置为 false Thread.currentThread().isInterrupted()：判断某个线程是否已被发送过中断请求，不会将中断标示位清除 如果一个线程处于了阻塞状态（如线程调用了 thread.sleep、thread.join、thread.wait、1.5 中的 condition.await、以及可中断的通道上的 I/O 操作方法后可进入阻塞状态），线程在检查中断标示时如果发现中断标示为 true，则会在这些阻塞方法调用处抛出 InterruptedException 异常，并且在抛出异常后立即将线程的中断标示位清除，即重新设置为 false。而如果线程处于非阻塞状态，则需要通过判断 Thread.interrupted() 或者 Thread.isInterrupted() 来循环检测 Synchronized 在获锁的过程中是不能被中断的，意思是说如果产生了死锁，则不可能被中断 LockSupport 的 park 方法阻塞，能够响应中断，但是不会抛出 InterruptedException 异常 一个支持中断线程的程序的标准处理模式 12345678910111213141516public void run() {​ try {​ // do something​ // 1. !Thread.currentThread().isInterrupted() 确保在非阻塞时能响应中断​ // 2. try-catch 后对 InterruptedException 处理确保阻塞时对中断进行处理​ while (!Thread.currentThread().isInterrupted()&amp;&amp; more work to do) {​ do more work ​ }​ } catch (InterruptedException e) {​ //线程在 wait 或 sleep 期间被中断了​ } finally {​ //线程结束前做一些清理工作​ }} 在之前所说的 acquire，ascquireShared 方法均不支持中断操作 123if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; 它们在 LockSupport.park 响应中断后只是置一个中断标记，但是并不会处理，仍然自旋获取锁直到获取成功或阻塞。而 acquireInterruptibly，acquireSharedInterruptibly 方法支持中断操作 123if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); 它们会在 LockSupport.park 响应中断后抛出 InterruptedException 异常结束线程 参考 AbstractQueuedSynchronizer 原理分析 - 独占/共享模式 AbstractQueuedSynchronizer的介绍和原理分析 AbstractQueuedSynchronizer源码解读","link":"/2019/01/10/AbstractQueuedSynchronizer同步器/"},{"title":"DNS是如何解析主机名的","text":"DNS 解析的作用就是将主机名转换为 IP 地址，那么 DNS 解析过程是怎么样的，DNS 服务器又是如何快速响应全球用户的请求的呢？ DNS 解析原理在解释 DNS 解析原理前首先需要知道的是，DNS 服务器只是一种统称，实际上 DNS 服务器的不同类型负责完全不同的功能，这对于后续理解整个原理具有非常关键的作用。下面根据 DNS 服务器功能不同主要分为 4 种类型： 根域名服务器：根域名服务器负责维护顶级域名（如 .com, .net, .org 等）对应的 TLD 域名服务器地址，即当客户端向其发送 DNS 解析请求时，根域名服务器会返回其顶级域名对应的 TLD 域名服务器地址。目前全球的根域名服务器的任播（Anycast）地址共有 13 个 TLD 域名服务器(顶级域名服务器)：不同顶级域名由不同的托管商负责，在根域名服务器响应了 TLD 域名服务器后的域名后，用户可以在 TLD 域名服务器获取到定向到权威服务器的信息，比如返回 zzcoder.cn 所在的权威服务器域名 权威服务器：权威服务器维护了特定顶级域名下的所有子域名（比如 zzcoder.cn）的 DNS 记录。比如用户在域名注册商(如 DNSPod)下注册 zzcoder.cn 实际上就是在权威服务器添加各类 DNS 记录（A 记录，CNAME 记录等等） 递归解析器：递归解析器也称为 DNS 解析器。递归解析器作为客户端与 DNS 域名服务器的中间人，是面向客户端最近的一站，它负责接收客户端的 DNS 查询，并分别向根域名服务器，TLD 域名服务器，权威服务器发送解析请求，然后将最终的响应返回给客户端。常见的公开的 DNS 解析器有 Google 的 8.8.8.8, Cloudflare 的 1.1.1.1 每个递归解析器都会内置 DNS 根域名服务器的 13 个 任播地址 假设我们的设备配置了 Google 的 8.8.8.8 DNS 解析器，当我们通过浏览器访问域名时，是怎么完成解析的呢？ 用户在浏览器中输入 zzcoder.cn，将向 8.8.8.8 DNS 递归解析器发送解析请求 DNS 解析器首先将顶级域名 .cn 向 DNS 根域名服务器请求解析返回其 TLD 域名服务器地址 DNS 解析器继续向 .cn 的 TLD 域名服务器请求二级域名 zzcoder.cn 对应的权威服务器地址 最后 DNS 解析器根据权威服务器返回的 DNS 记录响应给浏览器完成解析 上面的过程可以用下面的图比较清晰的解释，1，8 是 DNS 解析器和浏览器的交互，2-7是 DNS 解析器和域名服务器交互，9-10是 浏览器和目标网站的交互 如果对于图观察的比较细的话可以发现 DNS 解析器和客户端的交互（1，8）与 DNS 解析器和域名服务器的交互（2-7）箭头颜色不相同，这是因为它们分别对应两种不同类型的查询： 递归查询：在递归查询中，DNS 客户端要求 DNS 服务器（一般为 DNS 递归解析器）将使用所请求的 DNS 记录响应客户端，即 DNS 解析器不能返回低级别域名服务器的地址，必须返回其对应的 DNS 记录 迭代查询：在迭代查询中，DNS 客户端只需要 DNS 服务器返回其能够给出的最佳应答。比如 DNS 客户端向根域名服务器查询 zzcoder.cn，由于根域名服务器不知道权威服务器地址，因此它只需返回 .cn 对应的 TLD 服务器给客户端即可，后续的请求将由 DNS 客户端迭代发起 在上面这个图中，浏览器（客户端）向 DNS 解析器（8.8.8.8）发起的就是递归查询，而 DNS 解析器（8.8.8.8）向域名服务器发起的就是迭代查询。因此这里要注意理解，DNS 递归解析器本身做的实际上是迭代查询。 本地域名服务器（LDNS）也是经常被人提到的一个名词，实际上它是我们本地搭建的一个 DNS 解析器，然后在路由器或本机指向该 DNS 解析器替代 ISP 提供的 DNS 解析器或者公共 DNS 解析器。当然本地域名服务器不一定使用迭代查询，比如开源项目 smartdns 只是对 DNS 解析请求做了转发 DNS 缓存在上面已经把 DNS 解析的核心流程描述完了，实际上在 DNS 解析过程中会存在许多缓存来进一步提高解析速度： 浏览器缓存：浏览器缓存会对是 DNS 解析结果做一定的缓存，其作为 DNS 解析查询的第一步 操作系统级缓存：操作系统缓存作为是 DNS 解析的第二步，也是本地解析的最后一步。这个过程通常称为 “存根解析器”或 DNS 客户端。当存根解析器获取来自某个应用程序的请求时，其首先检查自己的缓存，以便查看是否有此记录。如果没有，则将本地网络外部的 DNS 查询（设置了递归标记）发送到 DNS 递归解析器。 路由器缓存：默认一般路由器的 DNS 常见设置是 192.168.0.1，所以 DNS 客户端实际上会往路由器发送解析请求，路由器本身并没有解析能力，它只会做一个转发以及缓存。当然这一层缓存不一定会走，比如我们可以在本机设备直接设置 DNS 服务器到 8.8.8.8 就不会走路由器了。 上面的几种缓存可以说是“客户端”的缓存，此时都不涉及 DNS 服务器。实际上 DNS 递归解析器也会缓存解析信息。当路由器接收到解析请求时默认会想 ISP 提供 DNS 递归解析器发送递归查询的请求，当 ISP 内的递归解析器收到 DNS 查询时，其还将查看所请求的主机到 IP 地址转换是否已经存储在其本地持久性层中，根据其缓存中具有的记录类型，递归解析器的解析过程会有所不同，比如： 如果此时解析器已存在其对应的权威域名服务器的 NS 记录（比如已经知道了 zzcoder.cn 所在权威服务器的地址 f1g1ns2.dnspod.net），那么此时解析器只需要向 f1g1ns2.dnspod.net 请求解析即可 如果此时解析器已存在对应的 TLD 服务器（比如 .cn）的地址，那么只需要请求 TLD 服务器和权威服务器即可 如果此时解析器没有对应 TLD 服务器的记录，才会额外查询根域名服务器 DNS 记录上面说的权威服务器保存了 DNS 记录，那么 DNS 记录是什么呢？常见的是 A 记录，CNAME 记录等，如下表所示： 记录类型 说明 A 地址记录，用于将主机名映射到其 IPv4 地址。 AAAA IPv6 地址记录，用于将主机名映射到其 IPv6 地址。 MX 邮件交换记录，用于将请求路由到邮件服务器。 NS 域名服务器记录，用于将 DNS 委托给权威服务器。 CNAME 规范名称记录，用于指定别名。 还有一种比较特殊的记录叫做胶水记录，胶水记录也是在域名注册商处创建的 DNS 记录。一般为域名服务器对应的 IP 地址 12345678910111213141516171819202122232425262728293031323334353637383940λ zhang [~] → dig zzcoder.cn @198.41.0.4; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; zzcoder.cn @198.41.0.4;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 57204;; flags: qr rd; QUERY: 1, ANSWER: 0, AUTHORITY: 8, ADDITIONAL: 11;; WARNING: recursion requested but not available;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;zzcoder.cn. IN A;; AUTHORITY SECTION:cn. 172800 IN NS c.dns.cn.cn. 172800 IN NS g.dns.cn.cn. 172800 IN NS b.dns.cn.cn. 172800 IN NS ns.cernet.net.cn. 172800 IN NS e.dns.cn.cn. 172800 IN NS f.dns.cn.cn. 172800 IN NS a.dns.cn.cn. 172800 IN NS d.dns.cn.;; ADDITIONAL SECTION:c.dns.cn. 172800 IN A 203.119.27.1g.dns.cn. 172800 IN A 66.198.183.65b.dns.cn. 172800 IN A 203.119.26.1ns.cernet.net. 172800 IN A 202.112.0.44e.dns.cn. 172800 IN A 203.119.29.1f.dns.cn. 172800 IN A 195.219.8.90a.dns.cn. 172800 IN A 203.119.25.1a.dns.cn. 172800 IN AAAA 2001:dc7::1d.dns.cn. 172800 IN A 203.119.28.1d.dns.cn. 172800 IN AAAA 2001:dc7:1000::1;; Query time: 220 msec;; SERVER: 198.41.0.4#53(198.41.0.4);; WHEN: Sun Jul 12 22:45:20 CST 2020;; MSG SIZE rcvd: 366 上述是对根域名服务器发起 DNS 解析请求，其中返回的 ADDITIONAL SECTION 会包含每个 TLD 服务器域名对应的 A 记录或 AAAA 记录，这些就是胶水记录。为什么需要它们呢？因为 DNS 解析过程中，无法通过域名来访问域名服务器，如果没有胶水记录，就需要额外根据域名服务器的域名先获取到域名服务器的 IP，这样才能进一步获取目标域名的 IP，因此域名服务器在向更高级别的域名服务器提供本地的域名的时候还会提供对应 IP 地址，以便在后续的 DNS 解析时防止出现循环。 DNS 的常见攻击DNS 是一种基于 UDP 的应用层协议，容易出现伪造，放大等攻击，以下是 DNS 比较常见的攻击： DNS 缓存投毒（污染）：这是将伪造的 DNS 数据引入 DNS 解析器缓存中的攻击，其将导致解析器返回域的错误 IP 地址。本质上攻击者只需要监听域名查询请求，一旦发现目标域名即可将自己伪装成目标域名的权威域名服务器返回虚假的查询结果，而 DNS 解析器一般都会有缓存机制，因此这个域名在 DNS 解析器缓存中就被污染了。 UDP 其中的一个特点是没有验证机制，非常容易伪装，当系统将 DNS 查询请求发出后，系统会接受第一个返回的结果作为使用，其后的将会被抛弃。因此投毒服务器只要快于真正的权威域名服务器返回即可 DNS 劫持：DNS 劫持的结果和 DNS 污染的结果类似，会返回虚假的解析结果，但是攻击手段不同，其目标是域名服务器上网站的 DNS 记录，而不是解析器的缓存。比如篡改 hosts 文件，ISP 对修改某些 DNS 解析记录，篡改DNS权威记录指向自己的恶意服务器以实现DNS劫持等等 DNS放大攻击：攻击者通常使用僵尸网络向公用的 DNS 解析器发送大量 DNS 查询请求，并伪造 IP 地址来源设置为受害者，再利用放大效果（比如发送者给 DNS 解析器 10 个字节，DNS 解析器返回 100 个字节），这样受害者的服务将收到大量且并不需要的 DNS 响应从而导致其崩溃，这也是 DDos 攻击的一种类型 DNS 污染问题不是不可避免的，比如现在流行的 DNSSEC 协议，DNSSEC 通过基于公共密钥加密的数字签名在 DNS 协议中新增了两项重要功能： 数据来源验证 - 解析器可以通过加密的方式验证收到的数据是否确实来自其认定的数据传送区域。 数据完整性保护 - 解析器可以确信，自区域所有者使用区域私钥初次进行数据签名以来，数据在传输过程中并未遭到修改。 篇幅原因这里不对该协议深入，有兴趣的人可以去研究更详细的原理 Anycast DNS之前提到目前全球的根域名服务器的任播（Anycast）地址共有 13 个，那么任播代表什么呢，又为什么需要任播呢？其实很简单，一般来说一个 IP 地址对应一个服务器，如果全世界只有 13 台服务器如果高性能的处理全世界的请求以及各种恶意攻击呢？再比如，公开的 DNS 解析器如 1.1.1.1 只需要一个 IP 却用来响应全球的所有请求，如果只有一台服务器如何支持这么高的并发呢？在 Anycast 中，一个 IP 地址可以应用于许多服务器。Anycast DNS 意味着一组 DNS 服务器中的任何一台都可以响应 DNS 查询，通常由地理位置最接近的一台提供响应。 这样的好处有几个： Anycast 网络对一个 IP 地址的请求可以由许多服务器答复，可以解决单台服务器的单点问题 Anycast 具有负载均衡能力，根据网络情况选择地理位置最接近的一台提供响应，有效减少响应延迟 Anycast 网络可以提供 DDoS 防护，因为流量可以分散到整个集群 DNS 智能解析如果使用 DNSPod（国内比较流行的域名解析厂商）就会发现它允许我们为同个域名设置多个 IP，并且允许设置在不同网络返回不同的 IP（比如国内/国外），那么它是怎么做到的呢？其实本质上 DNSPod 作为权威域名服务器它只需要知道请求解析的来源 IP 就可以根据地区来返回不同的 IP。因此类似 8.8.8.8 这样的 DNS 解析器在请求权威服务器的时候需要传入请求者 IP 这样就能完成智能解析，而这就是 EDNS 协议（edns-client-subnet）。它是一个 DNS 扩展协议，允许 DNS 解析器传递用户的 IP 地址给 Authoritative DNS server。DNSPod 支持了这种协议因此能够完成智能解析。比如我将 auto.zzcoder.cn 的境内解析到 6.4.7.8，境外解析到 9.8.3.4，此时分别通过国外/国内客户端 IP 来访问，并使用阿里 DNS 服务器 223.6.6.6 进行解析就会返回不同的结果 1234567891011121314151617181920212223242526272829303132333435363738394041424344λ zhang [~] → dig auto.zzcoder.cn +subnet=199.193.127.121 @223.6.6.6; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; auto.zzcoder.cn +subnet=199.193.127.121 @223.6.6.6;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 49896;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 1408; CLIENT-SUBNET: 199.193.127.121/32/24;; QUESTION SECTION:;auto.zzcoder.cn. IN A;; ANSWER SECTION:auto.zzcoder.cn. 600 IN A 9.8.3.4;; Query time: 40 msec;; SERVER: 223.6.6.6#53(223.6.6.6);; WHEN: Mon Jul 13 23:33:30 CST 2020;; MSG SIZE rcvd: 72λ zhang [~] → dig auto.zzcoder.cn +subnet=122.231.108.109 @223.6.6.6; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; auto.zzcoder.cn +subnet=122.231.108.109 @223.6.6.6;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 20362;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 1408; CLIENT-SUBNET: 122.231.108.109/32/24;; QUESTION SECTION:;auto.zzcoder.cn. IN A;; ANSWER SECTION:auto.zzcoder.cn. 600 IN A 6.4.7.8;; Query time: 52 msec;; SERVER: 223.6.6.6#53(223.6.6.6);; WHEN: Mon Jul 13 23:33:41 CST 2020;; MSG SIZE rcvd: 72 不是所有的 DNS 解析器和权威服务器都支持 EDNS","link":"/2020/07/12/DNS是如何解析主机名的/"},{"title":"HSDB从入门到实战","text":"HSDB（Hotspot Debugger)，是一款内置于 SA 中的 GUI 调试工具，可用于调试 JVM 运行时数据，从而进行故障排除 启动HSDB检测不同 JDK 版本需要使用不同的 HSDB 版本，否则容易出现无法扫描到对象等莫名其妙的问题 Mac：JDK7 和 JDK8 均可以采用以下的方式 1$ sudo java -cp ,:/Library/Java/JavaVirtualMachines/jdk1.7.0_80.jdk/Contents/Home/lib/sa-jdi.jar sun.jvm.hotspot.HSDB 事实上经过测试，即使通过 JDK8 自带的 sa-jdi.jar 去扫描对象（scanoops）的时候也会发生扫不到的情况，但可以通过其他手段代替 而 JDK11 的启动方式有些区别 1$ /Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home/bin/jhsdb hsdb 事实上经过测试，该版本启动的 HSDB 会少支持一些指令（比如 mem, whatis），因此目前不推荐使用该版本 Windows: 1$ java -classpath \"%JAVA_HOME%/lib/sa-jdi.jar\" sun.jvm.hotspot.HSDB 其中启动版本可以使用 /usr/libexec/java_home -V 获取 若遇到 Unable to locate an executable at “/Users/xx/.jenv/versions/1.7/bin/jhsdb” (-1) 可通过 Jenv 切换到当前 Jdk 版本即可解决 JVM参数设置HSDB 对 Serial GC 支持的较好，因此 Debug 时增加参数 -XX:+UseSerialGC，Debug 工具可以使用 IDE 或 JDB 获取应用进程idjps 仅查找当前用户的 Java 进程，而不是当前系统中的所有进程 1$ jps 默认显示 pid 以及 main 方法对应的 class 名称 -v：输出传递给 JVM 的参数 -l： 输出 main 方法对应的 class 的完整 package 名 CLHSDB常用指令 universe：查看堆空间信息 scanoops start end [type]：扫描指定空间中的 type 类型及其子类的实例 JDK8 版本的 HSDB 的 scanoops 会无法扫描到对象，但可以通过 GUI 界面的 Tools -&gt; Object Histogram，输入想要查询的对象，之后双击来获取对象的地址，也可以继续在里面点击 inspect 来查看对象信息 inspect：查看对象（OOP）信息【使用 tools-&gt;inspect，输入对象地址有更详细的信息哦】 revptrs：反向指针，查找引用该对象的指针 HSDB GUI界面可视化线程栈 对象直方图Tools -&gt; Object Histogram，我们可以通过对象直方图快速定位某个类型的对象的地址以供我们进一步分析 OOP信息我们可以根据对象地址在 Tools -&gt; Inspector 获取对象的在 JVM 层的实例 instanceOopDesc 对象，它包括对象头 _mark 和 _metadata 以及实例信息 堆信息我们可以通过 Tools -&gt; Heap Parameters 获取堆信息，可以结合对象地址判断对象位置 加载类列表我们可以通过 Tools -&gt; Class Browser 来获取所有加载类列表 元数据区HotSpot VM 里有一套对象专门用来存放元数据，它们包括： Klass 系对象，用于描述类型的总体信息【通过 OOP 信息（inspect）可以看到 instanceKlass 对象】 ConstantPool/ConstantPoolCache 对象：每个 InstanceKlass 关联着一个 ConstantPool，作为该类型的运行时常量池。这个常量池的结构跟 Class 文件里的常量池基本上是对应的 Method 对象，用来描述 Java 方法的总体信息，如方法入口地址、调用/循环计数器等等 ConstMethod 对象，记录着 Java 方法的不变的描述信息，包括方法名、方法的访问修饰符、字节码、行号表、局部变量表等等。注意，字节码指令被分配在 constMethodOop 对象的内存区域的末尾 MethodData 对象，记录着 Java 方法执行时的 profile 信息，例如某方法里的某个字节码之类是否从来没遇到过 null，某个条件跳转是否总是走同一个分支，等等。这些信息在解释器（多层编译模式下也在低层的编译生成的代码里）收集，然后供给 HotSpot Server Compiler 用于做激进优化。 Symbol 对象，对应 Class 文件常量池里的 JVM_CONSTANT_Utf8 类型的常量。有一个 VM 全局的 SymbolTable 管理着所有 Symbol。Symbol 由所有 Java 类所共享。 生成class文件到对应类下点击 create .class 后就可以在执行 HSDB 的目录下看到生成的 class文件，适合查看动态代理生成的字节码 实战分析对象存储区域下面代码中的静态变量，成员变量分别存储在什么地方呢？ 123456789101112131415161718192021public class Main { private static VMShow StaticVmShow = new VMShow(); private VMShow objVmShow = new VMShow(); public static void main(String[] args) { fn(); } private static VMShow fn(){ return new VMShow(); }}class VMShow { private int basicInt = 1; private Integer objInt = 2; private static Integer staticInt = 3; private String basicString = \"basicString\"; private static String staticString = new String(\"staticString\");} 首先查看对象直方图可以找到三个 VMShow 对象 那么如何确定这三个地址分别属于哪些变量呢？首先找静态变量，它在 JDK8 中是在 Class 对象中的，因此我们可以找它们的反向指针，如果是java.lang.Class 的那么就是静态变量 我们可以从 ObjTest 的 instanceKlass 中的镜像找到 class 对象来验证是否是该对象的 class 那么成员变量和局部变量如何区分呢？成员变量会被类实例引用，而局部变量地址则在会被被放在栈区 那么局部变量的反向指针都是 null，怎么确定它就被栈区所引用呢？我们可以看可视化线程栈 分析字符串字面量存储区域12345678910public class StringTest { public static void main(String[] args) { String s1 = \"a\"; String s2 = \"b\"; String s3 = s1 + s2; String s4 = new String(\"ab\"); System.out.println(s4); }} 上面一共涉及的字符串字面量和实例分别存储在什么地方呢？ 首先在 s2 处打上断点，启动 HSDB 监控该进程 打开对象直方图发现只有 1 个 a 的字符串对象 查找 StringTable 中 a 的对象地址 1jseval &quot;st = sa.vm.stringTable;st.stringsDo(function (s) { if (sapkg.oops.OopUtilities.stringOopToString(s).matches(&apos;^(a)&apos;)) {print(s + &apos;: &apos;);s.printValueOn(java.lang.System.out); println(&apos;&apos;)}})&quot; 可以根据需要改变 matches 中的值来匹配 可以看到这个对象地址就是 StringTable 中引用的地址 然后打断点在 sout 上，重新开始监控进程 重新使用对象直方图查看 String 值 这里有5个值，ab 有3个： ab 字面量 其中 s3 相当于 new StringBuild().append(&quot;a&quot;).append(&quot;b&quot;).toString()，会创建一个 ab 的实例 s4会创建一个 ab 的实例 我们重新打印 StringTable 相应的值来验证 1jseval &quot;st = sa.vm.stringTable;st.stringsDo(function (s) { if (sapkg.oops.OopUtilities.stringOopToString(s).matches(&apos;^(a|b).?&apos;)) {print(s + &apos;: &apos;);s.printValueOn(java.lang.System.out); println(&apos;&apos;)}})&quot; 那么运行时常量池中存放的是哪些呢？实际上它和 StringTable 一样是这些对象的引用，只不过 StringTable 是全局共享的，而运行时常量池只有该类的一些字面量。我们通过加载类列表可以查看 分析String.intern1234567891011121314public class StringInternTest { public static void main(String[] args) { String s1 = new String(\"he\") + new String(\"llo\"); // 1 s1.intern(); // 2 String s2=\"hello\"; // 3 System.out.println(s1==s2); // true String s3 = new String(\"1\") + new String(\"2\"); // 4 String s4 = \"12\"; // 5 s3.intern(); // 6 System.out.println(s3 == s4); // false }} 上述在编译器确定的字面量有 he, llo, hello, 1, 2, 12，但在真正执行到语句前，符号引用不一定解析成直接引用，即字面量对应的对象会在执行到语句时（idc 指令）才会创建 首先看通过加载类列表查看字节码指令： line bci bytecode 7 0 new #2 [Class java.lang.StringBuilder] 7 3 dup 7 4 invokespecial #3 [Method void ()] 7 7 new #4 [Class java.lang.String] 7 10 dup 7 11 ldc #5(0) [fast_aldc] 7 13 invokespecial #6 [Method void (java.lang.String)] 7 16 invokevirtual #7 [Method java.lang.StringBuilder append(java.lang.String)] 7 19 new #4 [Class java.lang.String] 7 22 dup 7 23 ldc #8(1) [fast_aldc] 7 25 invokespecial #6 [Method void (java.lang.String)] 7 28 invokevirtual #7 [Method java.lang.StringBuilder append(java.lang.String)] 7 31 invokevirtual #9 [Method java.lang.String toString()] 7 34 astore_1 8 35 aload_1 8 36 invokevirtual #10 [Method java.lang.String intern()] 8 39 pop 9 40 ldc #11(2) [fast_aldc] 9 42 astore_2 10 43 getstatic #12 [Field java.io.PrintStream out] 10 46 aload_1 10 47 aload_2 10 48 if_acmpne 55 10 51 iconst_1 10 52 goto 56 10 55 iconst_0 10 56 invokevirtual #13 [Method void println(boolean)] 12 59 new #2 [Class java.lang.StringBuilder] 12 62 dup 12 63 invokespecial #3 [Method void ()] 12 66 new #4 [Class java.lang.String] 12 69 dup 12 70 ldc #14(3) [fast_aldc] 12 72 invokespecial #6 [Method void (java.lang.String)] 12 75 invokevirtual #7 [Method java.lang.StringBuilder append(java.lang.String)] 12 78 new #4 [Class java.lang.String] 12 81 dup 12 82 ldc #15(4) [fast_aldc] 12 84 invokespecial #6 [Method void (java.lang.String)] 12 87 invokevirtual #7 [Method java.lang.StringBuilder append(java.lang.String)] 12 90 invokevirtual #9 [Method java.lang.String toString()] 12 93 astore_3 13 94 ldc #16(5) [fast_aldc] 13 96 astore #4 14 98 aload_3 14 99 invokevirtual #10 [Method java.lang.String intern()] 14 102 pop 15 103 getstatic #12 [Field java.io.PrintStream out] 15 106 aload_3 15 107 aload #4 15 109 if_acmpne 116 15 112 iconst_1 15 113 goto 117 15 116 iconst_0 15 117 invokevirtual #13 [Method void println(boolean)] 16 120 return 可以看到确实有 6 个idc，但如果我们在第一行语句打上断点，会发现它们都不在 StringTable（但这里的 he 在，它可能被其他类用到了），然后执行第一行，会发现 he 和 llo 在了，但 hello 不在 1jseval &quot;st = sa.vm.stringTable;st.stringsDo(function (s) { if (sapkg.oops.OopUtilities.stringOopToString(s).matches(&apos;^(he|llo|hello|1|2|12)&apos;)) {print(s + &apos;: &apos;);s.printValueOn(java.lang.System.out); println(&apos;&apos;)}})&quot; 但是 hello 对象还是存在的（new） 接着执行 s1.intern 会将 hello 对象的地址放入 StringTable 再执行 String s2=&quot;hello&quot;; 会发现 hello 对象仍然只有一个，都指向同一个。 而继续在 6 打断点，即执行完 String s4 = &quot;12&quot;;，因为 12 不在字符串常量池，那么会新建一个 12 的实例，并让字符串常量池引用它，这样会发现就有两个 12 了","link":"/2019/12/06/HSDB从入门到实战/"},{"title":"HTTP协议与无状态","text":"大家常提起 HTTP 协议是无状态的，其指代的“无状态”是什么？常见的观点有： 无状态代表相同的请求参数总是能返回相同的结果 HTTP 本身的设计是无状态的，增加了有状态协议头（Cookie/Session）后变成了有状态协议 对于第一个观点显而易见是错误的，它的表示更倾向于“幂等性”，这往往无法由协议本身保证，还需要服务器进行“有状态”的响应（若服务器不进行状态的持久化，当然无法做到幂等）；而第二个观点听起来就靠谱很多，通过 Cookie/Session 进行状态维护从而保证了有状态。但我们可以考虑下 Cookie 或 Session 保证的是谁的状态？一般情况下，它们保证了后端服务器的状态，而非 HTTP 协议的状态。因此对于最初的问题 HTTP 协议的”无状态“，我们是不是应该从协议的本身出发呢？ 什么是”无状态“协议对于”有状态“协议来说，多次请求间往往包含关联，就比如之前提到的服务端依赖 Cookie/Session 进行状态维护来保证关联，但区别在于有状态协议的状态维护应由协议本身来保证，换句话说，“有状态”协议本身存在会话（Session），一般和连接绑定的。比如 TCP 连接，传输双方是需要进行”有状态“交互（双方在三次握手后均进行状态信息的保存），且会话会随着连接断开而结束。反过来说，“无状态”协议本身不存在会话概念，其每个请求无论在哪个连接都是完全独立且正确的（即不会和先前的请求产生关联）。 Cookie/Session 所带来的会话不属于协议本身的状态，协议本身也无法应用这些状态。这种状态可以理解为应用程序基于协议实现的”有状态“应用 众所周知 HTTP 协议是利用 TCP 进行数据传输的，那么是否利用 TCP 进行数据传输的协议都是”有状态“协议呢？当然不是，因为它们本身并没有强关联，HTTP 并不是基于 TCP 的协议，它们处于 OSI 的不同层次（HTTP 协议属于应用层协议，TCP 协议属于传输层协议），如果你想的话，也通过命名管道提供 HTTP 服务，因此即使 TCP 协议是“有状态”的，也不能以此判断 HTTP 协议也是“有状态”的。 HTTPS 协议本质上是在应用层和传输层中间加入了 SSL 协议（严格来说，HTTPS 协议不算单独的协议），SSL 协议本身也需要通过握手（身份验证）来保持会话，因此 SSL 协议也是”有状态“协议 HTTP 协议是”无状态“协议吗？分清楚”有状态“/”无状态“协议后，我们可以分析一下 HTTP 协议是否为”无状态“协议： HTTP/1.0 时代每个 TCP 连接只能发送一个请求，因此无法在连接中产生会话的概念，显而易见 HTTP/1.0 协议属于“无状态”协议。 HTTP/1.1 时代引入了持久连接，即 TCP 连接默认不关闭，可以被多个请求复用。但此时的连接复用仅仅是为了提高传输效率，keep-alive 的默认情况下，它的若干个请求会排队串行化单线程处理，即后面的请求等待前面请求的返回才能获得执行机会，除此之外没有任何优化，因此 HTTP/1.1 协议也属于“无状态”协议。 HTTP/1.1 实际上还支持 pipeline，即连续发送一组没有相互依赖的请求而不必等到上一个请求先结束，但它仍然存在线头阻塞的问题（响应仍然得串行化），使用这项特性需要浏览器支持，且仍然没有对会话的支持 HTTP/2.0 时代的报头压缩（HPACK，即客户端和服务器都维护之前看见的标头字段的列表），GOAWAY 帧或流控的特性都标志着会话的诞生，因此 HTTP/2.0 协议属于“有状态”协议。 参考 Stateless protocol HTTP/2.0 Stream States","link":"/2020/05/31/HTTP协议与无状态/"},{"title":"SELECT FOR UPDATE语句深度解析","text":"&emsp;&emsp;Mysql 的 SELECT ... FOR UPDATE 语句是日常使用较多的用于锁定资源，确保在多个事务读取数据时始终能够读取到最新版本的数据的有效语句。那么它是怎么实现呢？在经过官网文档以及大量实践的验证之后发现网上存在大量不严谨甚至错误的信息，因此通过本文对 SELECT FOR UPDATE 语句作出以下总结。在具体介绍之前，先对目前网上教程或博客中会提到的几个常见误区进行纠正： SELECT FOR UPDATE 在xx情况下会添加表级锁。 请注意，在任何情况下 SELECT FOR UPDATE 都不会添加表级锁。事实上，在大部分情况下（DQL 语句，DML 语句，DDL 语句）都不会添加表锁，取而代之的是各种类型的行锁。 &emsp;&emsp;那么我们如何获取表锁呢？语句如下： 12LOCK TABLES xx READ; # 为 xx 表添加表级 S 锁LOCK TABLES xx WRITE; # 为 xx 表添加表级 X 锁 然后我们可以通过以下语句来检测当前 Mysql 有哪些表获取了表级锁 1SHOW OPEN TABLES WHERE In_use &gt; 0 更多的表级锁相关知识请参考官网介绍 SELECT FOR UPDATE 在未使用索引时会”锁表”。 SELECT FOR UPDATE 确实可以通过 Next-key lock 锁住所有记录和间隙来实现和表锁类似的效果。但未使用索引并非充分条件，我们判断 SELECT FOR UPDATE 是否锁住了所有数据和间隙还需要看它的隔离级别。 那么影响我们判断 SELECT FOR UPDATE 语句持有什么锁的因素有哪些呢？在这里列出以下几点： 隔离级别（RC/RR） 执行计划（聚簇索引/唯一索引/二级索引/无索引） 过滤条件（等值条件/范围条件） 以下分析内容均建立在已经了解 Mysql 的行级锁的类型和作用范围的基础上，同时列出几点必要的前提论据： 一般情况下，RC 级别是无法使用 Gap Lock 的，但在检查外键约束或者 duplicate key 检查时还是会用到的 Gap locking can be disabled explicitly. This occurs if you change the transaction isolation level to READ COMMITTED. Under these circumstances, gap locking is disabled for searches and index scans and is used only for foreign-key constraint checking and duplicate-key checking. MySQL 8.0 Reference Manual15.7.1 InnoDB Locking 一般情况下，执行计划根据某个索引查询后，会将过滤完的记录加锁后返回给 MySQL Server 进行过滤。在 RC 隔离级别下，当记录不满足条件时 MySQL Server 会调用 handler::unlock_row() 告诉存储引擎释放锁（破坏了 2PL 规则），RR 隔离级别下则会保持到事务提交 2PL（两阶段加锁协议）是数据库中保证事务并发的控制方法，即保证多个事务在并发的情况下等同于串行的执行。它将加锁和解锁分为两个阶段。而为了在事务中能够明确的判断什么是加锁阶段，什么是解锁阶段，引入了 S2PL（Strict-2PL），即在事务中只有提交（commit）或者回滚（rollback）时才是解锁阶段，其余时间为加锁阶段。 ICP（索引条件下推）：是一种减少 server 层和 engine 层之间交互的次数的优化方式。上面提到一般情况下对于根据索引查询返回的记录将交由 MySQL Server 进行过滤，而如果过滤条件是联合索引且无法走联合索引时，如： 123# 联合索引：(index1, index2, index3)# 根据最左匹配原则无法走联合索引select x from xx where index1 = ‘xx’ and index3 like ‘%xxxx%’ 正常情况下在对 index1 进行筛选后的记录就要返回。而经过 ICP 优化，由于 where 的查询列属于该联合索引，那么会将对该 where 条件记录过滤后才返回给 server 层 参考： MySQL 加锁处理分析 MySQL · 引擎特性 · InnoDB 事务锁系统简介 MySQL 8.0 Reference Manual 8.2.1.5 Index Condition Pushdown Optimization SELECT FOR UPDATE does not release locks of untouched rows in full table scans RC级别下的SELECT FOR UPDATE虽然 Mysql 默认的事务隔离级别是 RR，但是在大多数互联网应用中 Mysql 的隔离级别会设置为 RC，因此我们也首先讨论 RC 隔离级别下的 SELECT FOR UPDATE。 在执行计划不走索引时，将只会为满足条件的记录添加 Record Lock 执行计划不走索引代表 sql 会走聚簇索引的全扫描，对所有记录加锁后返回给 MySQL Server 进行过滤。过滤过程中不满足条件的记录的锁会被释放，因此最终只锁住了满足条件的记录 在执行计划走聚簇索引时，将只为满足条件的记录添加 Record Lock 在执行计划走唯一索引或二级索引时，将会为满足条件的记录所在的聚簇索引和二级索引添加 Record Lock 为什么还需要在聚簇索引加锁呢？因为如果不锁聚簇索引意味着别的事务可以使用 update/delete，那么就失去了锁定资源的作用了 从上面的分析可以看出，在 RC 级别下任何情况下都不会出现”锁表”效果。但是请注意即使 SELECT FOR UPDATE 的目标记录没有被锁住，也是有可能造成阻塞的。原因在于 Mysql 对非索引过滤（即是由 Mysql Server 过滤）的记录加锁返回的过程是不会省略的，因此如果 SELECT FOR UPDATE 不走索引，那么 Mysql 会为聚簇索引的所有数据行尝试添加 Record Lock ，而一旦有任何一行已经被锁定，那么当前查询就会被阻塞。 RR级别下的SELECT FOR UPDATEMysql 的 RR 级别为了解决幻读引入了 Gap Lock，这也为 SELECT FOR UPDATE 的加锁增加了很多可能性 在执行计划不走索引时，将会聚簇索引中的所有记录添加 Next-key Lock，相当于”锁表” RR 级别下非索引过滤的记录即使不符合过滤条件，锁也不会被释放。同时为了解决幻读，记录添加 Next-key Lock 来锁定间隙 在执行计划走聚簇索引时，若是能够命中的等值查询，将只为满足条件的记录添加 Record Lock；否则将覆盖范围包含过滤范围的记录添加 Next-key Lock。 为什么只有在等值查询是才有可能添加 Record Lock ？因为范围查询内的数据存在幻读问题 在执行计划走唯一索引时，锁住唯一索引的方式和聚簇索引相似，同时使用 Record Lock 锁住命中的聚簇索引 为什么只需要使用 Record Lock 锁住聚簇索引？因为通过唯一索引可以保证过滤范围间无法插入数据（与插入意向锁互斥），因此只需要 Record Lock 锁来确定目标记录不被 update/delete 即可 在执行计划走二级索引时，无论是否为等值查询都会为覆盖范围包含过滤范围的记录添加 Next-key，同时使用 Record Lock 锁住命中的聚簇索引 为什么二级索引不区分等值查询呢？因为即使是等值查询也不能唯一定位二级索引中的数据，在一棵二级索引的 B+ 树中，叶子结点由 二级索引列值 + 主键值 确定的，仅仅依靠二级索引列值还是相当于范围查询 Serializable下的SELECT FOR UPDATESerializable 级别下 SELECT FOR UPDATE 的加锁方式基本和RR级别相同。比较特殊的是，Serializable 下是不存在快照读的，即使查询语句不添加 for update 也会为记录添加共享锁 锁分析工具Mysql 提供了语句来查询当前持有锁的状态和类型等等，是验证我们的判断的利器。语句如下： 1SELECT * FROM performance_schema.data_locks 它提供几个关键信息： LOCK_TYPE：锁类型，RECORD 代表行锁，TABLE 代表表锁 LOCK_MODE：锁模式，X,REC_NOT_GAP 代表 Record Lock , X, GAP 代表 Gap Lock , X 代表 Next-key Lock INDEX_NAME：锁定索引的名称 LOCK_DATA：与锁相关的数据，比如锁在主键上就是主键值 更多的字段解释参考 MySQL 8.0 Reference Manual 26.12.12.1 The data_locks Table 除此之外，Mysql 还提供了查询当前正在执行的每个事务（不包括只读事务）的信息，比如隔离级别，内存中此事务的锁结构占用的总大小等等。语句如下： 1SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX 它提供几个关键信息： TRX_ID：如果是非锁定的只读事务是没有该 id 的 TRX_REQUESTED_LOCK_ID：当前事务正在等待的锁 id TRX_TABLES_LOCKED：当前 SQL 语句具有行锁定的表的数量 TRX_LOCK_MEMORY_BYTES：内存中此事务的锁结构占用的总大小。 TRX_ISOLATION_LEVEL：当前事务的隔离级别 更多的字段解释参考 MySQL 8.0 Reference Manual 25.39.29 The INFORMATION_SCHEMA INNODB_TRX Table","link":"/2019/06/18/SELECT-FOR-UPDATE语句深度解析/"},{"title":"Reactor模式","text":"标准 I/O 会存在两个阶段：（以 TCP Socket 举例） 数据在内核态和用户态的复制：TCP 协议栈维护着 Send Buffer（发送缓冲区）和 Recv Buffer（接收缓冲区），因此 read/write 都只是将用户态数据复制到内核态的 Socket Buffer(Send/Recv Buffer)。而 Socket Buffer 和网卡之间会通过 DMA 进行数据传输（不占用 CPU） 等待数据就绪：对于 read 操作来说，就绪是指 Recv Buffer 没有可读的数据；而对于 write 操作来说，就绪是指 Send Buffer 已满无法写入 BIO 称为同步阻塞 I/O，它在上述的两个阶段均会阻塞。因此 BIO 必须为每个 TCP 连接创建新线程并阻塞等待其可读或可写。服务端若想支持大量客户端连接，在 BIO 的前提下使用多线程来解决是必然的事情，下面用一个简单的例子展示： 123456789101112131415161718ExecutorService executor = Executors.newFixedThreadPool(100);try(ServerSocket serverSocket = new ServerSocket(8080)) { while (true) { Socket socket = serverSocket.accept(); executor.execute(() -&gt; { try(BufferedReader reader = new BufferedReader(new InputStreamReader(socket.getInputStream()))) { decode(); process(); encode(); write(); } catch (IOException e) { e.printStackTrace(); } }); }} catch (IOException e) { e.printStackTrace();} 在连接数不多的情况下，上述例子并无不妥。但是在高并发下呢？关键点在于线程 每个线程占用 256K～1M 的空间，高并发下存在大量的连接会占用大量的内存 过多的线程会使得 CPU 调度成本很高，CPU 将会疲于调度导致 CPU sy 使用率特别高 因此我们回过头来考虑一个很重要的问题，有必要为每个连接创建一个线程吗，这些阻塞等待I/O 的线程有意义吗？假如大部分连接都不会同时处于活跃状态（即此时连接并无读写事件发生），那么线程实际上在做无用的等待；而假如并发活跃连接数非常大，那么会存在大量的线程执行 write/read，此时会存在大量用户态数据和内核态的 Socket Buffer 互相复制的操作，该操作需要消耗 CPU。既然是依赖于 CPU，那么创建大量线程并没有正向作用，反而应该选择和 CPU 核心数类似的线程数。因此不管从哪个角度来说，为每个新连接都创建一个线程去阻塞等待读写都不是一个好选择。 那么理想的处理模型是怎么样的呢？关键的点是将本该由线程去阻塞等待可读可写变成异步以及回调处理，这就依赖于两个技术点： NIO：作为同步非阻塞 I/O，它在等待就绪阶段是非阻塞的，在内核态和用户态的复制阶段是同步阻塞的。通过 NIO 能保证线程不会做无用的等待 I/O 多路复用：只要应用通过系统调用通知内核所需监听的连接以及事件，内核能够在监听连接可读写时回调通知应用程序 注意，这里提到的 I/O 多路复用和 HTTP2 中的 Multiplexing 并不是一个概念，HTTP2 中的 Multiplexing 代表同个 TCP 连接可以复用来支持多个 HTTP 请求并发请求，而 I/O 多路复用(也可以理解为 I/O 多路传输) 代表使用单循环来处理多个连接，比如 select, epoll I/O多路复用Linux 为 I/O 多路复用提供了多个系统调用，如 select，poll，epoll。以 Linux 提供的 select 系统调用举例： 1int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); 构建 select 需要传入三个 fd(文件描述符) 数组分别指向内核需要对可读、可写和异常等事件进行监听的对应的描述符集合。调用 select 函数后，就会阻塞的等待事件到来。当 select 返回时应用需要遍历所有的 fd 来寻找发生事件的 socket。 select 有一些比较明显的缺点： 应用每次调用 select 都需要传入所有的 fd（最大个数不能超过1024个），这会导致这三个数组频繁的从用户态复制到内核态 内核每次都需要遍历所有的 fd 去检查就绪的事件 select 返回后应用程序需要遍历 fd 数组获取真正发生事件的 fd 而后续出现的 epoll 解决了上面几个痛点，它会在内核中维护一个数据表以避免每次都需要传入 fd 数组（减少了数据复制），同时也去除了 fd 个数的限制，并且 epoll 只会返回被触发的事件对应的 fd 从而避免应用程序去做额外的扫描和过滤。 但是不管是哪种实现方式，I/O 多路复用的基本使用方式都是：注册 -&gt; 监听事件 -&gt; 回调处理，因为只有应用先向内核注册感兴趣的事件以及 socket，内核才会在事件发生时回调应用。 Reactor 模式Reactor 模式是基于事件驱动的网络编程模式，能用少量的线程支持大量的连接，它也可以理解为 NIO 和 I/O 多路复用的最佳实践，在诸如 Netty 等网络编程框架已支持了 Reactor 的多种模式。单线程 Reactor 基本原理如下： 上图存在几个角色： Reactor：可以理解为事件分派器，维护多路复用器，监听并分派事件到对应的 Handler Acceptor：处理连接事件，负责向多路复用器注册感兴趣事件 Handler：处理读写就绪事件，包含 read, decode，process，encode, send 等处理，也可以向多路复用器注册感兴趣事件（比如写就绪） 通过单线程版 Reactor 模式可以使用单个线程就完成 Server 端的所有处理逻辑，而不再需要为每个连接创建一个新线程。但在实际应用中还需要做更多的优化： Handler 中的 read/write 这些操作由于是在接收到就绪事件后调用的，所以 I/O 操作大部分时间会使用 CPU 的，因此实际上可以构建和 CPU 核心数相同的线程数来提高 CPU 利用率 Handler 中的 process 业务处理操作可能存在其他阻塞 I/O 操作，比如 DB，RPC 等，因此可以创建 Worker 线程池进行处理，其线程数可大于 CPU 核心数 因此优化后的 Reactor 模式将 read/write 操作交由其线程数等于 CPU 核心数的线程池处理，而业务处理逻辑交由单独的 Worker 线程池处理。而这就是多线程 Reactor 模式（有些地方也称为主从 Reactor 模式）的原理 Main Reactor 仍然使用单线程处理，只不过这次它只需要处理新连接就绪事件 Sub Reactor 使用和 CPU 核心数相等的线程池负责读写事件的监听以及分配 Handler 的 I/O 部分（实际上 decode/encode 也可以放在这里）和 Sub Reactor 处于同一线程 Handler 的业务处理部分交由 Worker 线程池处理（线程数可大于 CPU 核心数） 其实还可以考虑一下，Handler 的业务处理所在的 Worker 线程池实际上会为每个请求分配一个线程，那么它和最初的 BIO + 多线程的模式看起来结果是一样的，所以多线程 Reactor 模式还有意义吗？答案是肯定的，Reactor 模式能承载更高的并发连接，因为大部分情况下并不是所有的连接都会产生读写事件的，可能 10K 的连接只有 1K 的连接并发产生了读写，那么处理线程数就从 10K 降到了 1K，因此 Reactor 模式才能称得上高性能 I/O 模型 Netty 中的线程模型Netty 支持上述的两种 Reactor 模式。首先是单线程 Reactor 模式 123456NioEventLoopGroup mainReactor = new NioEventLoopGroup(1);ServerBootstrap bootstrap = new ServerBootstrap();bootstrap.group(mainReactor) .channel(NioServerSocketChannel.class) .localAddress(new InetSocketAddress(8080)) .childHandler(new ServerHandlerInitializer()); NioEventLoopGroup 实现了 ExecutorService，本身是一个线程池，所以设置 NioEventLoopGroup 线程数为 1，当 bootstrap.group 仅传入一个 group 时 Main Reactor 和 Sub Reactor 就会使用同个线程 1234@Overridepublic ServerBootstrap group(EventLoopGroup group) { return group(group, group);} 在 Sub Reactor 收到请求后会通过 ChannelHandler 链处理，默认情况下整个责任链传递过程都是同步的。而在多线程 Reactor 中的 Main Reactor 和 Sub Reactor 将会使用不同的 group 1234567NioEventLoopGroup mainReactor = new NioEventLoopGroup(1);NioEventLoopGroup subReactor = new NioEventLoopGroup(); # 默认创建一个 CPU * 2 线程数的线程池ServerBootstrap bootstrap = new ServerBootstrap();bootstrap.group(mainReactor, subReactor) .channel(NioServerSocketChannel.class) .localAddress(new InetSocketAddress(8080)) .childHandler(new ServerHandlerInitializer()); 此时其实不算真正的多线程 Reactor，因为 ChannelHandler 此时是和 Sub Reactor 使用同个线程的。因此需要用户在实现 ChannelHandler 时使用业务线程池进行处理或使用 Netty 提供的 EventExecutorGroup 来支持 Netty 提供的 EventExecutorGroup 会将不同的 Channel 绑定到固定的线程，后续该连接的所有请求都会在同一线程处理，因此若是为了提供并发连接的响应速度使用该线程池是可以的，但若是同个连接并发的请求（比如 HTTP2 的多路复用）是无法解决的，这时候应使用自定义线程池解决 拓展从 Reactor 模式对线程资源的复用也给我们了启示，在连接数比较大时应利用非阻塞 API 以及事件回调的方式来实现高性能，比如爬虫程序会产生大量的请求，可以实现基于 NIO 的异步 HttpClient 来复用线程，再比如类似 Dubbo 的 RPC 框架会维护大量的 TCP 长连接，因此这也可以通过 NIO 来复用线程。在使用 NIO 作为客户端的实践中过程中需要考虑的问题是如何找到响应对应的请求，比如 Dubbo 的实现： 每个请求都会生成一个唯一的请求 ID（RID），然后将 Channel 保存在 DefaultFuture 中，并放入 Map 维护 通过 NIO 非阻塞接口发送请求后，根据调用模式（同步/异步）来确定是否需要阻塞当前线程 同步调用模式下，在获取到 ResponseFuture 后由框架会自动调用 get 阻塞当前线程；异步调用模式下 Dubbo 会将 ResponseFuture 放入 RpcContext（线程上下文）交由用户自行调用 请求响应后将响应结果放入 DefaultFuture，然后唤醒阻塞线程（同步调用时）","link":"/2020/08/23/Reactor模式/"},{"title":"Static Nested Or Inner Classes","text":"在 Java 中，在一个类中声明另一个类则称为嵌套类，被声明为 static 的嵌套类称为静态嵌套类（static nested classes ），与之相对的非静态嵌套类被称为内部类(（inner classes ） 非静态嵌套类每个实例都包含一个额外指向外围对象的引用，换句话说，要实例化一个非静态嵌套类必须首先实例化外部类 静态嵌套类独立于外部类实例，可以看作嵌套在一个顶级类中的顶级类。因此，如果嵌套类不要求访问外部类的实例变量或方法，就要始终把 static 修饰符放在它的声明中，使它成为静态嵌套类。（如果该嵌套类不作为基类，那么更适合同时加上 final 修饰符）。JDK1.8 源码可见各种这样的设计，如 ReentrantLock 中 123static final class NonfairSync extends Sync { ...} 我们从四个方面来更详细的讨论它们的区别： 嵌套类访问外部类的范围 嵌套类本身定义变量的范围 实例化 同名覆盖 非静态嵌套类 非静态嵌套类和外部类的实例关联，可以直接访问外部类的所有方法和字段 123456789101112131415161718public class OuterClass { private static int i = 1; private int j = 2; public void display(){ System.out.println(\"OuterClass...\"); } class InnerClass { public void run(){ System.out.println(i); System.out.println(j); display(); } }} 同样由于非静态嵌套类和外部类的实例相关联，所以它不能自己定义任何静态成员 1234567891011public class OuterClass { class InnerClass { static int failedField = 1; // 编译错误 static void failedMethod(){ // 编译错误 } }} 需要先实例化外部类，再实例化非静态嵌套类 12OuterClass outerClass = new OuterClass();OuterClass.InnerClass innerClass = outerClass.new InnerClass(); 同名覆盖问题，非静态嵌套类仅会出现在实例变量或方法中，非静态嵌套类中声明的实例同名变量或方法会覆盖外部类的声明，访问外部类的实例变量或方法需要加上 外部类名.this，如 OuterClass.this.x 123456789101112131415161718192021222324public class OuterClass { private int j = 2; public void display(){ System.out.println(\"OuterClass...\"); } class InnerClass { private int j = 3; public void run(){ System.out.println(this.j); // 3 System.out.println(OuterClass.this.j); // 2 this.display(); // InnerClass.. OuterClass.this.display(); // OuterClass... } public void display(){ System.out.println(\"InnerClass...\"); } }} 静态嵌套类 静态嵌套类和外部类（非实例）相关联，因此仅能访问外部类的静态变量和方法 1234567891011121314151617181920212223public class OuterClass { private static int staticField = 1; private int normalField = 2; public static void staticMethod(){ } public void normalMethod() { } static class StaticNestedClass { public void display() { System.out.println(staticField); // 编译通过 System.out.println(normalField); // 编译错误 staticMethod(); // 编译通过 normalMethod(); // 编译错误 } } 由于静态嵌套类不依赖于外部类实例，所以它可以定义任意变量和方法（和普通类相同） 1234567891011121314151617public class OuterClass { static class StaticNestedClass { int i = 1; static int j = 2; public void normalDisplay() { System.out.println(i); System.out.println(j); } public void staticDisplay(){ System.out.println(j); } } } 可以直接实例化静态嵌套类，且不会实例化外部类 1OuterClass.StaticNestedClass staticNestedClass = new OuterClass.StaticNestedClass(); 同名覆盖问题，静态嵌套类仅会出现静态变量或方法重名，静态嵌套类中声明的静态同名变量或方法会覆盖外部类的声明，访问外部类的静态变量或方法需要加上外部类名，如 OuterClass.x 123456789101112131415public class OuterClass { static int j = 4; static class StaticNestedClass { static int j = 2; public void display() { System.out.println(i); // 1 System.out.println(j); // 2 System.out.println(OuterClass.j); // 4 } }} 最后关于序列化，根据 Oracle 官方建议，强烈不推荐序列化非静态嵌套类，原因参考 Nested Classes 应用场景当一个类的构造函数需要传入多个参数，且很多参数是可选的，传统做法是重载构造函数。这将导致几个问题 由于可选参数多，因此会有大量重载构造函数，也就是说会存在大量重复代码 客户端调用比较困难，使用者需要选择合适的构造函数，以及了解每个参数的含义和顺序 因此比较合适的方式是使用 Builder 模式代替重载构造函数，它隐藏了内部的具体构建细节，允许多个可选参数，具有很强的可读性。而 Builder 模式就是使用静态嵌套类实现的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120@Getterpublic class BaseVideoParseBo { /** * 电影 */ private String movie; /** * 搜索链接 */ private String searchUrl; /** * 电影标题 */ private String title; /** * 时长 */ private String time; /** * 清晰度 */ private String bagde; /** * 封面 */ private String imgUrl; /** * 视频链接 */ private List&lt;String&gt; videoUrls = new ArrayList&lt;&gt;(); /** * 渠道 */ private String channel; protected BaseVideoParseBo(Builder&lt;?&gt; builder) { this.movie = builder.movie; this.bagde = builder.bagde; this.searchUrl = builder.searchUrl; this.time = builder.time; this.title = builder.title; this.imgUrl = builder.imgUrl; this.channel = builder.channel; } public static class Builder&lt;T extends Builder&lt;T&gt;&gt; { private Class&lt;T&gt; subBuilder; private String movie; private String searchUrl; private String title; private String time; private String bagde; private String imgUrl; private String channel; public Builder(Class&lt;T&gt; subBuilder) { this.subBuilder = subBuilder; } public T movie(String movie) { this.movie = movie; return self(); } public T searchUrl(String searchUrl) { this.searchUrl = searchUrl; return self(); } public T title(String title) { this.title = title; return self(); } public T time(String time) { this.time = time; return self(); } public T bagde(String bagde) { this.bagde = bagde; return self(); } public T imgUrl(String imgUrl) { this.imgUrl = imgUrl; return self(); } public T channel(String channel) { this.channel = channel; return self(); } private T self() { return subBuilder.cast(this); } public BaseVideoParseBo build() { return new BaseVideoParseBo(this); } } public void addVideoUrls(List&lt;String&gt; videoUrls) { this.videoUrls.addAll(videoUrls); } public void addVideoUrl(String videoUrl) { this.videoUrls.add(videoUrl); }} 构建该类对象代码如下： 1234// 仅使用基类时BaseVideoParseBo baseVideoParseBo = new BaseVideoParseBo.Builder&lt;&gt;(BaseVideoParseBo.Builder.class) .xxx() .build(); 这里再做一些拓展，可以看到上述类大量使用了泛型，其主要用于解决 Builder 继承时的返回类型问题，因此结合了 Builder 模式和协变返回类型，其子类可以如下实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Getterpublic class SubParseBo extends BaseVideoParseBo { /** * 是否获取所有清晰度的视频 */ private boolean allVideos; private String dataId; private String dataInfo; private String videoId; protected SubParseBo(Builder builder) { super(builder); this.dataId = builder.dataId; this.allVideos = builder.allVideos; } public static class Builder extends BaseVideoParseBo.Builder&lt;Builder&gt; { private boolean allVideos; private String dataId; public Builder() { super(Builder.class); } public Builder dataId(String dataId) { this.dataId = dataId; return this; } public Builder allVideos(boolean allVideos) { this.allVideos = allVideos; return this; } @Override public SubParseBo build() { return new SubParseBo(this); } } public void setDataInfo(String dataInfo) { this.dataInfo = dataInfo; } public void setVideoId(String videoId) { this.videoId = videoId; }} 那么构建子类对象如下代码： 123SubParseBo parseBo = new SubParseBo.Builder() .xxx .build();","link":"/2019/12/06/Static-Nested-Or-Inner-Classes/"},{"title":"ReentrantLock","text":"&emsp;&emsp;ReentrantLock 是基于 AQS 同步器实现的互斥锁，它支持设置公平锁/非公平锁模式，同时具有可重入性。在这里讨论 ReentrantLock 对这些特性的支持及应用。 标准模式12345678910111213141516171819class X { private final ReentrantLock lock = new ReentrantLock(); public void m() { lock.lock(); try { // ... method body } finally { lock.unlock(); } }} 简介ReentrantLock 默认使用非公平锁，也可以通过显式的使用公平锁 1234567public ReentrantLock() { sync = new NonfairSync();}public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync();} 公平锁 FairSync 和非公平锁 NonfairSync 均继承于内部类 Sync，而 Sync 继承 AQS（AbstractQueuedSynchronizer）锁。获取锁和释放锁均在 Sycn 中实现 12345678910111213141516public void lock() { sync.lock();}public boolean tryLock() { return sync.nonfairTryAcquire(1);}public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException { return sync.tryAcquireNanos(1, unit.toNanos(timeout));}public void unlock() { sync.release(1);} 非公平锁12345678910111213141516171819202122232425262728293031323334353637383940414243static final class NonfairSync extends Sync { private static final long serialVersionUID = 7316153563782823691L; final void lock() { if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); } protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires); }}abstract static class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = -5179523762034025860L; abstract void lock(); /** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */ final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; } return false; }} 在之前的 AQS同步器 提到过，AbstractQueuedSynchronizer 为子类提供了需要实现的 tryAcquire 模板方法，非公平锁获取锁调用的底层核心方法是 nonfairTryAcquire。首先基于 AQS 实现获取互斥锁的标准实现：当 state 为 0 时代表没有线程持有锁，因此尝试获取锁，如果获取锁成功则将当前线程设为持有锁的线程： 1234567int c = getState();if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; }} 但和普通的互斥锁不同的是，ReentrantLock 还需要支持可重入性：当 state 不为 0（即存在线程持有锁），会继续判断持有锁的是否为当前线程，如果是则允许当前线程获取锁，并将 state + 1。 1234567else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true;} 那么释放逻辑也需要对重入性额外处理 123456789101112protected final boolean tryRelease(int releases) { int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free;} 首先确保释放锁的线程为持有锁的线程，接下去确保重入次数和释放次数相同（即 state = 0）才认为释放锁完成，才会将持有锁的线程设为空。 &emsp;&emsp;ReentrantLock 的非公平锁模式意味着多个线程获取锁的顺序并不是按照申请锁的顺序，会存在“线程饥饿”的问题 公平锁1234567891011121314151617181920212223242526272829303132static final class FairSync extends Sync { private static final long serialVersionUID = -3000897897090466540L; final void lock() { acquire(1); } /** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */ protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { // 先判断当前线程是否位于等待队列中的第一个 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; } return false; }} 公平锁和非公平锁唯一的区别在于，它通过 hasQueuedPredecessors 确保当前线程是否位于等待队列中的第一个时才会尝试竞争锁 12345678910111213141516if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true;}public final boolean hasQueuedPredecessors() { // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());} 那么也就是说公平模式的获取锁会先判断当前线程是否位于等待队列中的第一个，若不是则直接加入等待队列来确保多个线程按照申请锁的顺序来获取锁 &emsp;&emsp;公平模式可以解决线程饥饿问题，但相比非公平模式，也会使得更多的线程阻塞，产生更多 CPU 唤醒阻塞线程的开销而影响吞吐量 ConditionCondition 是一个多线程间协调通信工具类，在 AQS 中实现，子类可以创建 Condition 实现类 123final ConditionObject newCondition() { return new ConditionObject();} await123456789101112131415161718192021222324252627public final void await() throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); // 添加到 Condition 队列 Node node = addConditionWaiter(); // 释放锁 int savedState = fullyRelease(node); int interruptMode = 0; // 判断是否在 AQS 队列，如果不在则阻塞 // 唤醒时会将当前线程重新插入 AQS 队列尾 while (!isOnSyncQueue(node)) { LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } // 自旋获取锁直到重新阻塞 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode);} Condition 存在自己的队列，在 Condition 队列就意味着线程需要 signal 方法唤醒。await 方法主要做以下几步： 将当前线程加入 Condition 队列尾 释放锁，即从 AQS 队列中退出（因此线程不会同时存在于 AQS 队列和 Condition 队列） 阻塞当前线程等待唤醒（唤醒时会将当前线程重新插入 AQS 队列尾，然后当它的前驱结点释放锁后 unpark 唤醒，唤醒后自旋/阻塞获取锁） signal1234567891011public final void signal() { // 确保当前线程持有锁 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) // 将 Condition 队列中的首结点加入 AQS 队列 doSignal(first);} signal 方法用于唤醒处于 Condition 队列中的首结点，但注意它并不是立刻唤醒 123456789101112131415161718192021222324private void doSignal(Node first) { do { // 移除头结点 if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; } while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null);}final boolean transferForSignal(Node node) { if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; Node p = enq(node); int ws = p.waitStatus; // 仅在前驱节点的状态处于取消状态或设置前驱节点状态为 SIGNAL 失败时才会直接唤醒 // 大部分情况都不会在这里唤醒 if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;} signal 方法的主要逻辑如下： 首先它会将头结点从 Condition 队列取出 然后通过 enq 将当前线程加入 AQS 队列尾 仅在前驱节点的状态处于取消状态或设置前驱节点状态为 SIGNAL 失败时才会直接唤醒，否则是等待它在 AQS 队列的前驱结点释放锁后唤醒（这样它的前驱结点为头结点，它才有资格获取锁，唤醒才有意义） signalAll1234567891011121314151617public final void signalAll() { if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignalAll(first);}private void doSignalAll(Node first) { lastWaiter = firstWaiter = null; do { Node next = first.nextWaiter; first.nextWaiter = null; transferForSignal(first); first = next; } while (first != null);} signalAll 和 signal 的区别就在于它会遍历 Condition 队列，把所有 Condition 队列中的结点放入 AQS 队列等待唤醒。 应用一个经典的应用：生产者/消费者模式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import java.util.LinkedList;import java.util.Queue;import java.util.Random;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.ReentrantLock;public class ProducerConsumer { private Queue&lt;Integer&gt; queue; private Integer max; private final ReentrantLock lock = new ReentrantLock(); private final Condition empty = lock.newCondition(); private final Condition full = lock.newCondition(); public ProducerConsumer(Queue&lt;Integer&gt; queue, Integer max) { this.queue = queue; this.max = max; } public void produce(){ new Thread(() -&gt; { Random random = new Random(); for(;;){ lock.lock(); try { while (queue.size() &gt;= max) { try { full.await(); } catch (InterruptedException e) { e.printStackTrace(); } } int num = random.nextInt(); if(queue.size() &gt;= max) { break; } queue.offer(num); empty.signalAll(); }finally { lock.unlock(); } } System.out.println(\"Not safe\"); }).start(); } public void consume(){ new Thread(() -&gt; { for(;;) { lock.lock(); try { while (queue.isEmpty()) { try { empty.await(); } catch (InterruptedException e) { e.printStackTrace(); } } queue.poll(); full.signalAll(); } finally { lock.unlock(); } } }).start(); } public static void main(String[] args) { Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;(); int max = 10; ProducerConsumer producerConsumer = new ProducerConsumer(queue, max); producerConsumer.produce(); producerConsumer.produce(); producerConsumer.consume(); producerConsumer.consume(); }} 正常情况，不会出现 Not safe &emsp;&emsp;Synchronized + wait/notify 的组合和 Lock + Condition 组合具有类似的功能，性能上的差别也不是很大，但它们仍然有许多区别。这里举几个典型的例子： Lock + Condition 可以选择公平/非公平模式，而 Synchronized + wait/notify 只能是非公平的 Lock + Condition 可以唤醒指定 Condition，而 Synchronized + wait/notify 不能指定 Lock + Condition 可以设置超时时间，而 Synchronized + wait/notify 只能等待唤醒或中断","link":"/2019/01/14/ReentrantLock/"},{"title":"内存屏障","text":"&emsp;&emsp;现代计算机大多数采用多核处理器或多处理器以提高性能，同时每个处理器通常存在一层或多层高速缓存，这将会更进一步加快对数据的访问。但是这也带来了新的挑战，即同一数据在不同处理器之间并不保证一致。所以为了保证数据的可见性，内存屏障应运而生。它能够刷新或使本地处理器高速缓存失效，以便查看其他处理器进行的写入的最新值或使该处理器的写入对其他处理器可见。而 Java 内存模型用于屏蔽不同硬件所带来的内存访问差异，以实现程序在不同平台能保证一致的并发效果。那么在并发环境下如何正确的使用内存屏障成为了首要问题。 硬件内存架构Java 内存模型是对硬件内存模型的抽象，因此理解它需要一些硬件基础知识。这里主要介绍 处理器的存储器结构 和 处理器的高速缓存与缓存一致性 随机访问存储器（RAM）随机访问存储器（RAM），是用于和 CPU 交换数据的内部存储器。根据存储单元的工作原理不同可以分为两类： 动态的存储器（DRAM） 静态的存储器（SRAM） SRAM 比 DRAM 更快，但也更贵，因此 SRAM 主要作为高速缓存存储器（Cache，如 CPU 的 L1，L2），而 DRAM 则作为计算机主存。而我们常说的内存指的就是是计算机的主内存 DRAM。 总线（Bus）总线是一组并行的导线，能携带地址，数据和控制信号，用于计算机各种功能部件（CPU，DRAM，I/O 设备等）之间传送信息。根据传输的信息种类，计算机的总线可以划分为数据总线、地址总线和控制总线。CPU 则是通过数据总线与内存交换数据的（即通信） CPU 和主存（DRAM）之间的数据传送称为总线事务，读事务代表从主存传送数据到 CPU，写事务代表从 CPU 传送数据到主存。 它们同个两条总线连接起来，一条是系统总线（连接 CPU 和 I/O 桥接器），一条是内存总线（连接 I/O 桥接器和 DRAM），其中 I/O 桥接器会将系统总线的电子信号翻译成内存总线的电子信号。 读事务（movq A, %rax）： 首先 CPU 将地址 A 放到系统总线并通过 I/O 桥传递到内存总线 接着 DRAM 感受到内存总线的地址信号并读取地址，并将其对应的数据写回内存总线通过 I/O 桥传递到系统总线 最后 CPU 感觉到系统总线的数据并读取数据复制到寄存器中完成读事务。 写事务（movq %rax, A）： 首先 CPU 将地址 A 放到系统总线，DRAM 从内存总线读出地址，并等到数据到达 接着，CPU 将寄存器中的 %rax 放到系统总线 最后，DRAM 从内存总线读出数据，并存储到 DRAM 中 存储器层次结构以一个经典的存储器层次结构举例，所有现代计算机系统都是采用这种结构 从上至下，存储设备的速度变得更慢，容量更大。顶层是最快的寄存器，CPU 可以在一个时钟周期内访问，接下来是 L1 - L3 缓存（它们用的就是之前所说的 SRAM），然后就是计算机主存（DRAM），再往下就是磁盘等等。 而 Inter Core i7 中的高速缓存如下： Intel Core i7 处理器的的每个 CPU 芯片有 4 个核。每个核有自己私有的 L1，L2 高速缓存，所有的核共享 L3 统一高速缓存。 高速缓存的读和写略过把内存地址映射到快速缓存块的内容（这里不需要相关知识），高速缓存的读分为缓存命中和缓存不命中。 对于缓存命中，即当程序需要读取 K + 1 层的某个数据时，当前 K 层的缓存已经存在，那么直接读取数据 而对于缓存不命中，即 K 层没有存储数据，那么将从 K + 1 层缓存读取数据，同时如果 K 层的缓存已经满了，可能需要覆盖现存的块。如通过 LRU 算法替换被访问时间距现在最远的块。 而对于高速缓存的写则有两种方案 直写（write through） + 非写分配（not write allocate）： 直写：写命中时（即要写一个已经缓存的数据），同时写入缓存以及主内存 非写分配：写不命中时，不将写入位置读入缓存，直接将数据写入主内存 回写（write back） + 写分配（write allocate）： 回写：写命中时，只写入缓存，只在数据被替换出缓存时才会将数据写到主内存 写分配：写不命中时，将写入位置读入缓存，然后以写命中的方式进行写入（即回写） 有些（大多数是比较老的）CPU 只使用直写模式，有些只使用回写模式，还有一些，一级缓存使用直写而二级缓存使用回写。这样做虽然在一级和二级缓存之间产生了不必要的数据流量，但二级缓存和更低级缓存或内存之间依然保留了回写的优势。对于直写（write through），它需要一个写缓冲区（write buffer）将高速缓存写入的数据保存的主内存中 &emsp;&emsp;写缓冲区的作用类似于异步处理来提高性能，比如当 CPU 的写入速度比缓存响应的还快时则减少了等待的时间，大大提高性能；同时它还能聚合多个写入到同一个缓存块从而减少下一级缓存的流量 缓存一致性如果系统只有一个 CPU 核在工作，那么一些都没有问题。而如果一个 CPU 有多个核，且每个核都有自己的缓存，那么就会遇到问题：如果某个 CPU 缓存段中对应的内存内容被另外一个 CPU 改了，它无法感知到。而对于回写模式，写指令甚至会在执行过后很久才会真正写到 DRAM 中，这就造成了多组缓存不一致的问题。 &emsp;&emsp;注意，这个问题的原因不在于多核而在于多组缓存。假如多个 CPU 核共用一组缓存，是不会存在这个问题的 为了保证缓存一致性，MESI 协议就出现了。MESI 是四种缓存段状态的首字母缩写，任何多核系统中的缓存段都处于只有四种状态：失效（Invalid）缓存段，共享（Shared）缓存段，独占（Exclusive）缓存段，已修改（Modified）缓存段。 失效（Invalid）缓存段: 要么已经不在缓存中，要么它的内容已经过时。为了达到缓存的目的，这种状态的段将会被忽略。一旦缓存段被标记为失效，那效果就等同于它从来没被加载到缓存中。 共享（Shared）缓存段，它是和主内存内容保持一致的一份拷贝，在这种状态下的缓存段只能被读取，不能被写入。多组缓存可以同时拥有针对同一内存地址的共享缓存段，这就是名称的由来。 独占（Exclusive）缓存段，和 S 状态一样，也是和主内存内容保持一致的一份拷贝。区别在于，如果一个处理器持有了某个 E 状态的缓存段，那其他处理器就不能同时持有它，所以叫“独占”。这意味着，如果其他处理器原本也持有同一缓存段，那么它会马上变成“失效”状态。 已修改（Modified）缓存段，属于脏段，它们已经被所属的处理器修改了。如果一个段处于已修改状态，那么它在其他处理器缓存中的拷贝马上会变成失效状态，这个规律和E状态一样。此外，已修改缓存段如果被丢弃或标记为失效，那么先要把它的内容回写到内存中——这和回写模式下常规的脏段处理方式一样。 该协议保证：只有当缓存段处于 E 或 M 状态时处理器才能去修改它，也就是说只有这两种状态下，处理器是独占这个缓存段的。当处理器想写某个缓存段时，如果它没有独占权，它必须先发送一条“我要独占权”的请求给总线，这会通知其他处理器，把它们拥有的同一缓存段的拷贝失效。 而如果有其他处理器想读取这个缓存段，独占或已修改的缓存段必须先回到“共享”状态。如果是已修改的缓存段，那么还要先把内容回写到内存中。 也就是说，MESI 保证一旦某个缓存段被回写修改后（M 状态），任意缓存级别的所有缓存段的内容和它对应的内存内容一致 写缓冲区和失效队列缓存一致性已经能够保证对单个地址的读写的内存上的完整一致性，但是同步等待其他处理器指令返回影响了处理性能。因此在寄存器和 L1 缓存之间会有读写缓冲区（LoadBuffer, StoreBuffer），合称排序缓冲（Memoryordering Buffers ，MOB ）。它们使得 CPU 异步处理读写指令，即当前处理器不需要等待其他处理器的失效确认（Invalidate Acknowlege）返回，会直接处理接下去的指令。 比如 写指令：对于已处于 E（独占）状态的缓存行，CPU 会直接写入缓存行；而对于其他需要切换回 E 状态的情况，则首先向其他处理器发出失效指令，接着把要写入到主存的值写到 StoreBuffer，然后处理接下去指令。而 StoreBuffer 中的数据则等待失效确认（Invalidate Acknowlege）返回后统一刷新到内存。 读指令：对于处于 S（共享）状态的缓存行命中时，CPU 会直接读取缓存完成读指令；而对于其他状态需要切回 S 状态的情况，则会放入 LoadBuffer 中等待确认后处理 但是这会导致一个严重的问题： &emsp;&emsp;即使读写指令本身是按照顺序执行的，但最终仍然存在指令重排序 比如按顺序执行 A, B 两个写指令，A 写指令所在缓存行处于 S 状态，B 写指令所在缓存行处于E状态，那么 B 会比 A 先完成写入操作；又或者按顺序执行 C, D 两个读指令，C 读指令所在缓存行处于 I 状态，D 读指令所在缓存行处于 S 状态，那么 D 会比 C 先完成读取操作。 同时处理器执行失效也不是一个简单的操作，它需要占用处理器的时间，如果接受的 invalidate 请求过多，cpu 处理速度就跟不上，因此又出现了失效队列（invalidate queue），它保证： 对于所有的收到的 Invalidate 请求，Invalidate Acknowlege 消息必须立刻发送返回 Invalidate 并不真正执行，而是被放在一个失效队列中，在方便的时候才会去执行。 当然，这里必须不能太慢。也就是说，cpu 实际上给出了一个承诺，如果一个 invalidatge 请求在 invalidate queue 中，那么对于这个请求相关的 cacheline，在该请求被处理完成前，cpu 不会再发送任何与该 cacheline 相关的 MESI 消息。 同样这也会导致一个严重的问题： &emsp;&emsp;读取的时候有可能会读到过时的数据 比如 CPU0 执行写指令，它向 CPU1 发出失效指令，然后 CPU1 立刻返回失效确认，但实际上并未真正执行失效操作。这时 CPU0 则更新了缓存行，造成了不同处理器直接的数据不一致。 所以我们现在可以总结下目前遇到的问题： 乱序处理器在满足 As-if-Serial 特性的基础下，本身就不会严格按照程序的顺序向缓存发送内存操作指令，导致指令重排序。 Java 运行时环境的 JIT 编译器指令重排序 由于 store buffer 和 invalidate queue 导致的内存可见性问题（即内存重排序） &emsp;&emsp;As-if-serial 语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器，runtime 和处理器都必须遵守 as-if-serial 语义。比如： 123double pi = 3.14; // Adouble r = 1.0; // Bdouble area = pi r r; // C 这里例子中，A 和 B 可以重排序，但是 A 和 C，B 和 C 不行，因为它们存在数据依赖关系。但需要注意的是，控制依赖仍然会存在重排序，比如： 12345678910111213141516class ReorderExample {​ int a = 0;​ boolean flag = false; public void writer() { a = 1; //1 flag = true; //2 } Public void reader() { if (flag) { //3 int i = a * a; //4 …… } }} 看起来 3 和 4 存在控制依赖关系，不应该重排序，而实际上，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。这里 3 和 4 操作可能会被重排序为： 1234567// 先把计算结果临时保存到一个名为重排序缓冲（reorder buffer ROB）的硬件缓存中temp = a * a;if(flag){​ // 当flag为真后再赋值进去​ int i = temp } 那么它们会导致什么问题呢？我们以两个典型的案例来让问题显形： CPUB 依赖于 CPUA 发出的信号来执行逻辑 12345678910DRAM: x = 0; y = false;CPUA: x = 1; y = true; CPUB: if(y){ assert x = 1; } 这个案例有可能会出现 CPUB 断言错误的情况，可能原因有以下几种 由于指令重排序，CPUA 的两个写入指令重排序，导致 CPUB 读取到 y = true 时，x = 0 虽然指令未重排序，但由于 store buffer 的存在导致 CPUA 对 x = 1的指令写入主内存不及时使得 y = true 先被写入内存，那么 CPUB 就有可能读到老数据 虽然指令未重排序，但由于 invalidate queue 的存在导致虽然 Invalidate Acknowlege 返回后使得 store buffer 的数据已经回写到主存，但是由于失效消息未处理导致 CPUB 的缓存行仍有效，读到了老数据。 CPUA，CPUB 互相读取对方的写入 12345678910DRAM: x, y, r1, r2 = 0CPUA: x = 1; r1 = y; CPUB： y = 1; r2 = x; 和上述类似同样的原因，这个案例有可能会出现 r1 = r2 = 0 的情况。 为了解决上述案例产生的问题，内存屏障诞生 =͟͟͞͞( •̀д•́) 内存屏障JDK1.7 根据 store/load 指令的先后顺序将内存屏障分为以下四种： LoadLoad 屏障 防止 LoadLoad 屏障前后的读指令的指令重排序 处理器以阻塞的方式先处理失效队列的消息，防止读取到老数据 StoreStore 屏障 防止 StoreStore 屏障前后的写指令的指令重排序 处理器以阻塞的方式将当前存储缓存（store buffer）的值写回主存 LoadStore 屏障 防止 LoadStore 屏障前的读指令和屏障后的写指令的指令重排序 处理器以阻塞的方式先处理失效队列的消息，防止读取到老数据 在 JVM 中，实际上它和 LoadLoad 屏障作用是相同的，底层都是调用 acquire() 方法 StoreLoad 屏障 防止 StoreLoad 屏障前后的所有读写指令的指令重排序 处理器以阻塞的方式将当前存储缓存（store buffer）的值写回主存 处理器以阻塞的方式先处理失效队列的消息，防止读取到老数据 该屏障同时具备另三种屏障的作用，因此开销也最大。 它们并不是真正意义上的内存屏障，只是一种抽象的概念。在不同硬件中，内存屏障会有不同的实现。比如 x86 的 64 位 CPU 提供了 mfence, lfence, sfence 指令来提供内存屏障，而 x86 的 32 位 CPU 则不提供 mfence、lfence、sfence 三条汇编指令的支持。因此 Linux 内核定义 smp_mb, smp_rmb，smp_wmb 三种内存屏障来处理不同处理器架构（比如对于 X86-64 直接使用上述指令，而对于 X86-32 则通过 lock 前缀来实现） 案例重现了解了内存屏障的作用后，我们重新再来分析之前的两个案例 CPUB 依赖于 CPUA 发出的信号来执行逻辑 12345678910111213DRAM: x = 0; y = false;CPUA: x = 1; StoreStore() y = true; CPUB: if(y){ LoadLoad() assert x = 1; } 我们在 CPUA 和 CPUB 的程序中分别插入 StoreStore 屏障和 LoadLoad 屏障。它们能保证以下三点： CPUA 的写写指令，CPUB 的读读指令不能重排序 CPUA 写入 x 变量的值后保证将 store buffer 缓存的数据写回主内存。即写入 x 到主内存一定先于 y CPUB 在读取到 y 的值后保证先处理 invalidate queue 的失效消息，即读取到 y 会重新从主内存获取最新的 x 的值 那么这就保证一个顺序链：x 写入到主存 &lt; y 写入到主存 &lt; y 从主存读取数据 &lt; x 从主存读取数据。也就意味值：一旦 CPUB 读取到 y = true，x 的值总是等于 1 CPUA，CPUB 互相读取对方的写入 123456789101112DRAM: x, y, r1, r2 = 0CPUA: x = 1; StoreLoad(); r1 = y; CPUB： y = 1; StoreLoad(); r2 = x; 我们在 CPUA 和 CPUB 的程序中都插入了 StoreLoad 屏障。它们能保证以下三点： CPUA 和 CPUB 均不会对写入 x 和读取 y 两个操作重排序 CPUA 和 CPUB 写入值后保证将 store buffer 缓存的数据写回主内存 CPUA 和 CPUB 读取值之前保证先处理 invalidate queue，即总是读到主内存的最新数据 那么我们可以推导出，当任一处理器执行到读取指令时，必定已经写入了当前值到主存且重新从主存读取数据，那么 r1 = r2 = 0 的情况也是不可能的了。 &emsp;&emsp;该案例必须使用 StoreLoad 屏障。因为 CPUA 的读的值依赖于 CPUB 的写，而 CPUB 的读的值也依赖于 CPUA 的写，那么就需要同时保证写的及时性和读的正确性了。而每个处理器同时插入两条屏障（LoadLoad 屏障，StoreStore 屏障）也是不行的，因为它们都不能保证读写指令的重排序。 volatile小解JMM 通过内存屏障实现了 volatile 的内存语义，这里简单的讨论它的两点特性 &emsp;&emsp;volatile 如何保证读取能读取到最新值？ 仅从 CPU 层面来看，单个变量能够保证最终一致性的，即总能在一定时间内读取到最新值，因此不会存在读不到最新值的情况。但由于 Java 的 JIT 即时编译器的存在，会使得生成的汇编指令总是从寄存器暂存的数据获取值（甚至直接将值定义为常量），因此会有即使变量在主存更新了依然无法读取到变量的最新值的情况。 &emsp;&emsp;寄存器不同于高速缓存，CPU 大多只能与寄存器交互（有些也可以和 L1 缓存交互，这里的高速缓存指的是无法直接交互的缓存），高速缓存的存在是因为 CPU 和主存交互太慢，需要缓存来提供性能。那么如果 CPU 始终从寄存器的暂存数据中读取，即使缓存是最终一致的，也会永远都不到最新值。 而 volatile 的读基于 C++ 的 volatile 实现： 1inline jint OrderAccess::load_acquire(volatile jint* p) { return *p; } 它是一种编译器屏障，会禁止编译器优化，生成的加载指令不能从寄存器取值，而是总是从内存中加载（虽然由于高速缓存的存在，实际上总是从缓存加载），而因为缓存是最终一致的，因此可以保证可见性。 &emsp;&emsp;volatile 如何保证写入最新值？ volatile 变量在写入后会插入 StoreLoad 屏障（lock 前缀的效果同 StoreLoad 屏障），即 1__asm__ volatile (&quot;lock; addl $0,0(%%rsp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;); 这样就保证了每次写入都会到主内存。 volatile 写之前会插入 StoreStore，防止和之前的任何写指令重排序 volatile 读之后会插入 LoadLoad，LoadStore 屏障，保证不和之后的读写指令重排序 至于原因，可以参考之前的两个案例。实际上通过 volatile 关键字就能保证上述两个案例的并发正确性 Final小解JMM 同样通过内存屏障在一些情景下实现 final 的内存语义，这里也简单的讨论下 初始读取共享对象与初始读取该共享对象的 final 成员变量之间不能重排序 123x = sharedRef; ... ; i = x.finalField; 当存在数据依赖关系时，编译器本身不会对它们重排序。但确实有一些处理器会对这种情况进行重排序，因此特别制定了这一规则 如果在构造函数中有一条 final 字段的 store 指令，同时这个字段是一个引用，那么它将不能与构造函数外后续可以让持有这个 final 字段的对象被其他线程访问的指令重排。…代表构建方法边界 123x.finalField = v; ... ; sharedRef = x;v.afield = 1; x.finalField = v; ... ; sharedRef = x; JMM 为了满足 final 的这种特殊规则，实际上就是加了一个 StoreStore 屏障 1x.finalField = v; ... ; StoreStore() sharedRef = x; 参考链接 深入理解计算机系统(第三版) Cache (computing) Wiki) 聊聊高并发（三十四）Java内存模型那些事（二）理解CPU快速缓存的工作原理 Cache写机制：Write-through与Write-back Write buffer Wiki why we use write buffer in mipscache? 缓存一致性（Cache Coherency）入门 CPU缓存一致性协议MESI Memory Barriers Are Like Source Control Operations linux-kernel-memory-barriers 内存屏障保证缓存一致性 Java内存访问重排序的研究 聊聊原子变量、锁、内存屏障那点事 LINUX内核之内存屏障 The JSR-133 Cookbook for Compiler Writers 指令重排序 Does the C++ volatile keyword introduce a memory fence? 彻底理解volatile","link":"/2018/12/22/内存屏障/"},{"title":"Tomcat 线程模型详解","text":"Tomcat 作为最常见的 Servlet 容器，在 6.x 版本就支持了 NIO 模式的 Connector 和 Reactor 模式相比有什么特殊之处吗？首先来看下面的表格： Java Nio Connector NIO Java Nio2 Connector NIO2 APR/native Connector APR Classname Http11NioProtocol Http11Nio2Protocol Http11AprProtocol Tomcat Version since 6.0.x since 8.0.x since 5.5.x Support Polling YES YES YES Polling Size maxConnections maxConnections maxConnections Read Request Headers Non Blocking Non Blocking Non Blocking Read Request Body Blocking Blocking Blocking Write Response Headers and Body Blocking Blocking Blocking Wait for next Request Non Blocking Non Blocking Non Blocking SSL Support Java SSL or OpenSSL Java SSL or OpenSSL OpenSSL SSL Handshake Non blocking Non blocking Blocking Max Connections maxConnections maxConnections maxConnections 这是从 Apache Tomcat 9 Configuration Reference-Connector Comparison 中得到的多种模式下的 Connector 的对比： NIO 就是我们熟悉的同步非阻塞 I/O 模型 NIO2 指的是 AIO，即异步 I/O 模型，其实 Netty 已经抛弃 AIO，至于原因根据 ISSUE-NIO.2 support 介绍主要还是 Linux 下技术不够成熟以及复杂度的考虑 ARP 实际上还是 NIO 模式，只不过它是基于 ARP（Apache Portable Runtime Libraries，由 C 写的 Apache 可移植运行时库）实现以提高性能。我们在启动 Tomcat 经常能看到 The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: 提示就是指需要我们安装指定的环境以便正常启动 ARP 模式，当然我们现在常见使用的还是 NIO 模式，所以可以忽略该条提示 我们主要关心的是 NIO 模式，而从表格中可以知道比较重要的点： Read Request Body/Write Response Headers and Body 是阻塞的 Read Request Headers/Wait for next Request 是非阻塞的 既然使用 NIO 模式为什么还要阻塞的读写数据呢？因为 Tomcat 是 Servlet 容器，Read Request Body/Write Response Headers and Body 是由 ServletInputStream 和 ServletOutputStream 定义的，而在 Servlet3.1 之前的规范中 ServletInputStream 和 ServletOutputStream 是阻塞的。 Tomcat 线程模型下图是 Tomcat 的整体线程模型： Acceptor：单线程阻塞监听连接事件，和 Multi-Reactor 模型的 Main Reactor + Acceptor 的作用相似 Poller：Acceptor 接收到的连接事件将通过 PollEvent 事件传递到 Poller 线程池处理，本质上就是将该 Socket 后续的读写事件交由 Poller 线程中的 Selector 进行监听并分派。Poller 线程池的线程池数为 CPU * 2，和 Multi-Reactor 模型的 Sub Reactor 的作用类似 在 Multi-Reactor 模型中，读写 I/O 也是在 Sub Reactor 中执行的，而在 Tomcat 中仅有 Http 请求头，请求行是在 Poller 中执行的 Worker（Servlet）：Poller 在解析完 Http 请求行，请求头后会将请求交由 Worker 业务线程池进行处理，默认情况下会创建最大线程数为 200 的线程池。当用户通过 ServletInputStream.read/write 读取 Request Body 或写入时将会向 Block Poller 注册监听读写事件，和 Multi-Reactor 模型的 Handler 的作用类似 Block Poller：这是 Multi-Reactor 模型没有的角色，单线程的监听向其注册的 Socket 的读写事件，当事件发生后将交由 Worker 线程阻塞读写。它主要是结合 Worker 线程实现基于 NIO 的模拟阻塞读写，在后文会通过源码进行解析 Servlet 规范导致 Tomcat 的线程模型和 Reactor 模式具有一定差距，在 Multi-Reactor 中，I/O 读写（Sub-Reactor 线程执行）和业务阻塞是分离的（Handler 所在业务线程执行），而 Tomcat 的 I/O 读写和业务阻塞均在同个 Worker 线程（也可以称为 Servlet 线程），这在业务阻塞时长比较大的情况下具有比较大的影响 源码解析阻塞读取Request BodyTomcat 的 Request Body 的读取是阻塞式的，调用 ServletInputStream.read 时会触发读取 Request Body，在 Tomcat 中的实现是 CoyoteInputStream.read。其内部会触发 ActiveFilter 链的调用 12345678910# org.apache.coyote.http11.Http11InputBuffer#doRead@Overridepublic int doRead(ApplicationBufferHandler handler) throws IOException { if (lastActiveFilter == -1) return inputStreamInputBuffer.doRead(handler); else return activeFilters[lastActiveFilter].doRead(handler);} 默认处理非 chunked 请求的 Filter 是 IdentityInputFilter chunked 请求：HTTP1.1 长连接模式下，为了能正确复用 TCP 连接，需要通过 Content-Length 或 chunked 来标志响应体大小，但诸如网络文件等要想准确获取长度需要生成完成才能确认，所以通过 chunked 分块编码来提高性能 12345678910111213141516171819202122232425262728293031323334# org.apache.coyote.http11.filters.IdentityInputFilter#doRead@Overridepublic int doRead(ApplicationBufferHandler handler) throws IOException { int result = -1; if (contentLength &gt;= 0) { if (remaining &gt; 0) { int nRead = buffer.doRead(handler); if (nRead &gt; remaining) { // The chunk is longer than the number of bytes remaining // in the body; changing the chunk length to the number // of bytes remaining handler.getByteBuffer().limit(handler.getByteBuffer().position() + (int) remaining); result = (int) remaining; } else { result = nRead; } if (nRead &gt; 0) { remaining = remaining - nRead; } } else { // No more bytes left to be read : return -1 and clear the // buffer if (handler.getByteBuffer() != null) { handler.getByteBuffer().position(0).limit(0); } result = -1; } } return result;} 这里插一句和线程模型无关的知识点，即如何判断 Http 请求已读取完成？根据上面的逻辑可以看出，Tomcat 在读取每个 Http 请求的时候是根据 Header 中的 Content-Length 来读取字节的，每次读取一定字节时会更新 remaining = remaining - nRead，当 remaining = 0 时代表当前 Http 请求的 Request Body 已读取完成，因此当 CoyoteInputStream.read 未返回 -1 时均代表当前 Http 请求未接收完整 其中 buffer.doRead(handler) 调用的实际上是 Http11InputBuffer.SocketInputBuffer#doRead 12345678910111213141516171819private class SocketInputBuffer implements InputBuffer { @Override public int doRead(ApplicationBufferHandler handler) throws IOException { if (byteBuffer.position() &gt;= byteBuffer.limit()) { // The application is reading the HTTP request body which is // always a blocking operation. if (!fill(true)) return -1; } int length = byteBuffer.remaining(); handler.setByteBuffer(byteBuffer.duplicate()); byteBuffer.position(byteBuffer.limit()); return length; }} 这里注意在调用 fill 方法时会传入 true，代表阻塞的获取 Http request body。去除无关的调用链，最终读取的关键位置在 NioSelectorPool#read，该方法通过 NIO 模拟阻塞 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# org.apache.tomcat.util.net.NioBlockingSelector#readpublic int read(ByteBuffer buf, NioChannel socket, long readTimeout) throws IOException { SelectionKey key = socket.getIOChannel().keyFor(socket.getPoller().getSelector()); if (key == null) { throw new IOException(sm.getString(\"nioBlockingSelector.keyNotRegistered\")); } KeyReference reference = keyReferenceStack.pop(); if (reference == null) { reference = new KeyReference(); } NioSocketWrapper att = (NioSocketWrapper) key.attachment(); int read = 0; boolean timedout = false; int keycount = 1; //assume we can read long time = System.currentTimeMillis(); //start the timeout timer try { while(!timedout) { if (keycount &gt; 0) { //only read if we were registered for a read read = socket.read(buf); if (read != 0) { break; } } try { if ( att.getReadLatch()==null || att.getReadLatch().getCount()==0) att.startReadLatch(1); poller.add(att,SelectionKey.OP_READ, reference); if (readTimeout &lt; 0) { att.awaitReadLatch(Long.MAX_VALUE, TimeUnit.MILLISECONDS); } else { att.awaitReadLatch(readTimeout, TimeUnit.MILLISECONDS); } } catch (InterruptedException ignore) { // Ignore } if ( att.getReadLatch()!=null &amp;&amp; att.getReadLatch().getCount()&gt; 0) { //we got interrupted, but we haven't received notification from the poller. keycount = 0; }else { //latch countdown has happened keycount = 1; att.resetReadLatch(); } if (readTimeout &gt;= 0 &amp;&amp; (keycount == 0)) timedout = (System.currentTimeMillis() - time) &gt;= readTimeout; } //while if (timedout) throw new SocketTimeoutException(); } finally { poller.remove(att,SelectionKey.OP_READ); if (timedout &amp;&amp; reference.key!=null) { poller.cancelKey(reference.key); } reference.key = null; keyReferenceStack.push(reference); } return read;} 上述代码逻辑为： 通过 socket.read(buf) 尝试进行读取一次，若读取成功则返回 若当前不可读，则通过 poller.add(att,SelectionKey.OP_READ, reference) 向 BlockPoller 注册 OP_READ 事件，然后通过 CountDownLatch 将当前 Worker 线程阻塞 由 BlockPoller 单线程监听 OP_READ 事件，在可读时唤醒 Worker 线程，由 Worker 线程进行读取 1234567891011121314151617181920212223# org.apache.tomcat.util.net.NioBlockingSelector.BlockPoller#runIterator&lt;SelectionKey&gt; iterator = keyCount &gt; 0 ? selector.selectedKeys().iterator() : null;// Walk through the collection of ready keys and dispatch// any active event.while (run &amp;&amp; iterator != null &amp;&amp; iterator.hasNext()) { SelectionKey sk = iterator.next(); NioSocketWrapper attachment = (NioSocketWrapper)sk.attachment(); try { iterator.remove(); sk.interestOps(sk.interestOps() &amp; (~sk.readyOps())); if ( sk.isReadable() ) { countDown(attachment.getReadLatch()); } if (sk.isWritable()) { countDown(attachment.getWriteLatch()); } }catch (CancelledKeyException ckx) { sk.cancel(); countDown(attachment.getReadLatch()); countDown(attachment.getWriteLatch()); }}//while 所以实际上 Request Body 的读取是由 Worker 线程阻塞读取完成的，至于 BlockPoller 其实类似 Poller，只不过它的 Selector 单独处理 Request Body 的读写事件 阻塞写入数据Tomcat 的写入同样是阻塞式的，由 ServletInputStream.write 时会触发，在 Tomcat 的实现类为 CoyoteOutputStream#write，其内部同样有个 OutputFilter 123456789# org.apache.coyote.http11.Http11OutputBuffer#flush@Overridepublic void flush() throws IOException { if (lastActiveFilter == -1) { outputStreamOutputBuffer.flush(); } else { activeFilters[lastActiveFilter].flush(); }} 默认情况下调用的是 IdentityOutputFilter.write 12345678910111213141516171819202122232425262728293031323334353637# org.apache.coyote.http11.filters.IdentityOutputFilter#doWrite@Overridepublic int doWrite(ByteBuffer chunk) throws IOException { int result = -1; if (contentLength &gt;= 0) { if (remaining &gt; 0) { result = chunk.remaining(); if (result &gt; remaining) { // The chunk is longer than the number of bytes remaining // in the body; changing the chunk length to the number // of bytes remaining chunk.limit(chunk.position() + (int) remaining); result = (int) remaining; remaining = 0; } else { remaining = remaining - result; } buffer.doWrite(chunk); } else { // No more bytes left to be written : return -1 and clear the // buffer chunk.position(0); chunk.limit(0); result = -1; } } else { // If no content length was set, just write the bytes result = chunk.remaining(); buffer.doWrite(chunk); result -= chunk.remaining(); } return result;} 这里同样插一句和线程模型无关的知识点，即如何判断 Http 请求已写入完成？根据上面的逻辑可以看出，Tomcat 在读取每个 Http 请求的时候是根据 Response Header 中的 Content-Length 来读取字节的，每次读取一定字节时会更新 remaining = remaining - nRead，当 remaining = 0 时代表当前 Http 请求的 Reponse 已写入完成 其中 buffer.doWrite(chunk); 调用的实际上是 Http11OutputBuffer.SocketOutputBuffer#doWrite 123456789101112131415# org.apache.coyote.http11.Http11OutputBuffer.SocketOutputBuffer#doWrite@Overridepublic int doWrite(ByteBuffer chunk) throws IOException { try { int len = chunk.remaining(); socketWrapper.write(isBlocking(), chunk); len -= chunk.remaining(); byteCount += len; return len; } catch (IOException ioe) { response.action(ActionCode.CLOSE_NOW, ioe); // Re-throw throw ioe; }} 这里的 socketWrapper.write(isBlocking(), chunk); 会使用阻塞的方式进行写入，最终写入的核心方法为 NioSelectorPool#write 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# org.apache.tomcat.util.net.NioBlockingSelector#writepublic int write(ByteBuffer buf, NioChannel socket, long writeTimeout) throws IOException { SelectionKey key = socket.getIOChannel().keyFor(socket.getPoller().getSelector()); if (key == null) { throw new IOException(sm.getString(\"nioBlockingSelector.keyNotRegistered\")); } KeyReference reference = keyReferenceStack.pop(); if (reference == null) { reference = new KeyReference(); } NioSocketWrapper att = (NioSocketWrapper) key.attachment(); int written = 0; boolean timedout = false; int keycount = 1; //assume we can write long time = System.currentTimeMillis(); //start the timeout timer try { while ( (!timedout) &amp;&amp; buf.hasRemaining()) { if (keycount &gt; 0) { //only write if we were registered for a write int cnt = socket.write(buf); //write the data if (cnt == -1) throw new EOFException(); written += cnt; if (cnt &gt; 0) { time = System.currentTimeMillis(); //reset our timeout timer continue; //we successfully wrote, try again without a selector } } try { if ( att.getWriteLatch()==null || att.getWriteLatch().getCount()==0) att.startWriteLatch(1); poller.add(att,SelectionKey.OP_WRITE,reference); if (writeTimeout &lt; 0) { att.awaitWriteLatch(Long.MAX_VALUE,TimeUnit.MILLISECONDS); } else { att.awaitWriteLatch(writeTimeout,TimeUnit.MILLISECONDS); } } catch (InterruptedException ignore) { // Ignore } if ( att.getWriteLatch()!=null &amp;&amp; att.getWriteLatch().getCount()&gt; 0) { //we got interrupted, but we haven't received notification from the poller. keycount = 0; }else { //latch countdown has happened keycount = 1; att.resetWriteLatch(); } if (writeTimeout &gt; 0 &amp;&amp; (keycount == 0)) timedout = (System.currentTimeMillis() - time) &gt;= writeTimeout; } //while if (timedout) throw new SocketTimeoutException(); } finally { poller.remove(att,SelectionKey.OP_WRITE); if (timedout &amp;&amp; reference.key!=null) { poller.cancelKey(reference.key); } reference.key = null; keyReferenceStack.push(reference); } return written;} 上述代码逻辑为： 通过 socket.write(buf) 尝试进行写入一次，若读取成功则返回 若当前不可写，则通过 poller.add(att,SelectionKey.OP_WRITE, reference) 向 BlockPoller 注册 OP_WRITE 写入事件，然后通过 CountDownLatch 将当前 Worker 线程阻塞 由 BlockPoller 单线程监听 OP_WRITE 事件，在可读时唤醒 Worker 线程，由 Worker 线程进行读取 1234567891011121314151617181920212223# org.apache.tomcat.util.net.NioBlockingSelector.BlockPoller#runIterator&lt;SelectionKey&gt; iterator = keyCount &gt; 0 ? selector.selectedKeys().iterator() : null;// Walk through the collection of ready keys and dispatch// any active event.while (run &amp;&amp; iterator != null &amp;&amp; iterator.hasNext()) { SelectionKey sk = iterator.next(); NioSocketWrapper attachment = (NioSocketWrapper)sk.attachment(); try { iterator.remove(); sk.interestOps(sk.interestOps() &amp; (~sk.readyOps())); if ( sk.isReadable() ) { countDown(attachment.getReadLatch()); } if (sk.isWritable()) { countDown(attachment.getWriteLatch()); } }catch (CancelledKeyException ckx) { sk.cancel(); countDown(attachment.getReadLatch()); countDown(attachment.getWriteLatch()); }}//while 所以写数据和读取 Request Body 是非常相似的过程 Servlet 异步接口上面提到了 Tomcat 的 I/O 读写和业务阻塞均在同个 Servlet 线程，这在业务阻塞时间较长时很容易出现 Tomcat 的 Worker 线程池任务堆积（默认最大 200 个线程），无法支撑高并发场景。而在 Servlet3.1 开始支持了非阻塞 I/O，示例代码如下： 1234AsyncContext actx = request.startAsync();actx.setTimeout(20000);ServletInputStream in = request.getInputStream();in.setReadListener(new MyReadListener(in,actx)); 通过异步模式可以将 I/O 读写和业务阻塞分离以达到复用 Worker 线程的作用。根据 Apache Tomcat Versions 的介绍，在 Tomcat8.x 中已经支持了 Servlet3.1 通过异步 Servlet 的支持，Tomcat 既解决了“一个连接一个请求”的问题，又解决高并发下业务阻塞会影响到读写线程的问题。当然对于如何使用异步 Servlet 以及 Tomcat 如何实现的感兴趣的话可以通过源码深入，本文不做过多介绍 Tomcat or NettyTomcat 属于 Servlet 容器，Netty 属于异步网络编程框架，但它们都能作为 web 容器。上面介绍了 Tomcat 的线程模型，那么和 Netty 相比，谁更适合做 Web 服务器呢？如果针对于 Http 协议，那么 Tomcat 是毫无疑问的，它对于 Http 有着更完善的支持，比如 Chunk 分块传输。而 Netty 是基于传输层的，所以可以支持更多的应用层协议。 那么 Tomcat 和 Netty 的线程模型谁更有优势呢？其实没有本质上的区别，Tomcat 的 NIO 模式和 Netty 的 Multi-Reactor 模式都解决了“一个连接一个线程”的问题，且默认模式下业务处理和 I/O 读写都是在同个线程 Netty 的默认模型并不是 Multi-Reactor 模型，业务处理默认情况下是和 Sub Reactor 处于同个线程 Tomcat 的读写均在 Worker 线程 所以容器可优化业务阻塞时间较长场景的方案是：采用业务阻塞和 I/O 阻塞分离的方式实现（异步 Servlet 或 Multi-Reactor 模式）。但这已经是容器优化的极限了，它仍然无法解决大量业务线程阻塞时间过长时仍然会导致大量的线程产生的问题。因此要想进一步提高性能，不能只看容器，而需要将业务阻塞（比如缓存，数据库，RPC 等）操作变为非阻塞操作以提高线程复用程度 拓展Http Request Body 是由用户在 Servlet 线程进行阻塞读取的，假如用户不主动读取上传的问题会出现什么情况呢，比如上传一个 100M 的文件 Tomcat 会自动接收吗？ 从 TCP 层面来看，如果数据一直不被接收，那么 Recv Buffer 会很快被占满，根据流量控制机制发送方将不会再发送数据，所以是不会自动接收所有数据的 从 Tomcat 层面来看，我们可以观察 IdentityInputFilter#end 方法 123456789101112131415161718192021222324252627282930# org.apache.coyote.http11.filters.IdentityInputFilter#end@Overridepublic long end() throws IOException { final boolean maxSwallowSizeExceeded = (maxSwallowSize &gt; -1 &amp;&amp; remaining &gt; maxSwallowSize); long swallowed = 0; // Consume extra bytes. while (remaining &gt; 0) { int nread = buffer.doRead(this); tempRead = null; if (nread &gt; 0 ) { swallowed += nread; remaining = remaining - nread; if (maxSwallowSizeExceeded &amp;&amp; swallowed &gt; maxSwallowSize) { // Note: We do not fail early so the client has a chance to // read the response before the connection is closed. See: // https://httpd.apache.org/docs/2.0/misc/fin_wait_2.html#appendix throw new IOException(sm.getString(\"inputFilter.maxSwallow\")); } } else { // errors are handled higher up. remaining = 0; } } // If too many bytes were read, return the amount. return -remaining;} 在请求结束后 Tomcat 会自动调用该方法，其代码如果缓存中存在剩余的字节，Tomcat 会自动读取，但是会有限制，默认只读取 2M(由 maxSwallowSize 确定)，如果请求体数据大于 2M，Tomcat 会抛出异常并关闭连接。 The maximum number of request body bytes (excluding transfer encoding overhead) that will be swallowed by Tomcat for an aborted upload. An aborted upload is when Tomcat knows that the request body is going to be ignored but the client still sends it. If Tomcat does not swallow the body the client is unlikely to see the response. If not specified the default of 2097152 (2 megabytes) will be used. A value of less than zero indicates that no limit should be enforced. ​ The HTTP Connector","link":"/2020/08/30/Tomcat-线程模型详解/"},{"title":"如何优雅的避免空指针","text":"123456789101112131415161718192021222324public class NPESolution { public void withIf(Person person){ if(person != null){ // ... } // ... } public void withSpringAssert(Person person){ Assert.isTrue(person != null, \"person must be not null.\"); // ... } public void withOptional(Person person){ Optional&lt;Person&gt; personOptional = Optional.ofNullable(person); // ... } public void withJsr305Annotation(@Nonnull Person person){ Optional&lt;Person&gt; personOptional = Optional.of(person); // ... }} 上述的代码是我在日常用于避免空指针（NPE）的常用方式，很长时间内我都热衷于断言（Assert）这类防御性编程方式，防御性编程可以有效的保证方法的输入条件，并在毫无意义的边界情况能够给出有效的提示，何乐而不为呢？事实上防御性编程也确实是一种非常推荐的方式，并且其在 Spring 源码中随处可见。而 JDK8 的 Optional 是否会是一种更优雅的方式呢？亦或许，另有它人？ if 语句是初学者最常使用的处理空指针的方式，直至今日它也在大多数场景被推荐使用。即使是如此简单的方式，其实也可以略微优化。下面是一个使用 if 语句的例子： 123456if(person == null){ // ...} else { // ...}return ...; 在现实业务中我们难以避免地会需要解决分支，if-else 是大多数人常用的方式。但是如果分支内部又产生了分支，我们的代码可读性就会大大的降低，因此这里提到的技巧就是“及时终止”。何谓“及时终止”，简单来说就是通过提前终止代码逻辑来减少嵌套 if-else 的复杂度。优化后的代码如下： 1234567if(person == null){ // ... return ...;} // ...return ...; 既然 if 语句已经能够解决空指针问题，那么为什么 Spring 这类开源项目要使用 Assert 呢？原因在于真实业务场景中，空指针这类的边界条件非常多，并且它很有可能对业务方法的毫无意义，因此使用 Assert 的方式会显得清晰明了，如： 12345678910111213141516171819202122232425262728293031323334// org.springframework.validation.beanvalidation.SpringValidatorAdapterpublic class SpringValidatorAdapter implements SmartValidator, javax.validation.Validator { /** * Create a new SpringValidatorAdapter for the given JSR-303 Validator. * @param targetValidator the JSR-303 Validator to wrap */ public SpringValidatorAdapter(javax.validation.Validator targetValidator) { Assert.notNull(targetValidator, \"Target Validator must not be null\"); this.targetValidator = targetValidator; } @Override public &lt;T&gt; Set&lt;ConstraintViolation&lt;T&gt;&gt; validate(T object, Class&lt;?&gt;... groups) { Assert.state(this.targetValidator != null, \"No target Validator set\"); return this.targetValidator.validate(object, groups); } @Override public &lt;T&gt; Set&lt;ConstraintViolation&lt;T&gt;&gt; validateProperty(T object, String propertyName, Class&lt;?&gt;... groups) { Assert.state(this.targetValidator != null, \"No target Validator set\"); return this.targetValidator.validateProperty(object, propertyName, groups); } @Override public &lt;T&gt; Set&lt;ConstraintViolation&lt;T&gt;&gt; validateValue( Class&lt;T&gt; beanType, String propertyName, Object value, Class&lt;?&gt;... groups) { Assert.state(this.targetValidator != null, \"No target Validator set\"); return this.targetValidator.validateValue(beanType, propertyName, value, groups); } ...} 当然 Assert 这类防御性编程方式的缺陷也非常明显，业务逻辑中会存在大量的判空逻辑，通过 Assert 代替 if 语句的方式会使得方法内部存在大量的防御性代码，这并不能提高代码质量，因此 防御性代码常用于输入参数校验。而业务逻辑中的 NPE 解决方案应该是 Optional 类，构建 Optional 对象的方式通常为 ofNullable 方法或 of 方法，它们的区别在于传入对象是否允许为空 12Optional&lt;Person&gt; personOptional = Optional.ofNullable(person);Optional&lt;Person&gt; personOptional = Optional.of(person); // null is not allowed 我们可以在 Optional 实现类中找到大量 防御性代码 + Optional.of() 组合使用的应用场景，如： 12345678// java.util.Optional#filterpublic Optional&lt;T&gt; filter(Predicate&lt;? super T&gt; predicate) { Objects.requireNonNull(predicate); // Assert 类似的效果 if (!isPresent()) return this; else return predicate.test(value) ? this : empty();} 基于上述的方式，我们可以基本完成一个比较优雅的避免空指针的模式了，并且当我们错误的传入空指针时，编译器（如 idea）会在运行期前及时的提醒我们方法不允许为空。那么这就够了么？还不够。在很多时候，我们会遇到遗留代码或提供三方jar 包，调用方往往会苦于无法确定传入参数是否允许为空，从而不得不研究方法实现。因此更优雅的方式是，我们对外提供的接口（public）可以通过标记注解来对接口进行说明，而此类注解同样能触发编译器的警告。JSR 305 规范已经提供了此类注解，我们只需引入 com.google.code.findbugs:jsr305 的 jar 包，就可以使用 @Nullable，@Nonnull，@CheckForNull 等标记注解了。 到此我们就实现了优雅避免空指针的方式： 12345public void withSmart(@Nonnull Person person){ Objects.requireNonNull(person, \"person must be not null.\"); Optional&lt;Person&gt; personOptional = Optional.of(person); // ...} 它能够为我们带来： @Nonnull（标志注解）：清晰的对外接口签名，并且能够触发 findBugs 或 idea 对代码运行期前的检查 Objects.requireNonNull（防御性代码）：在触发边界条件时提供有意义的异常警告 Optional：提供优雅的业务逻辑判空实现 由于私有方法不会对外暴露，所以私有方法可以只使用 Optional类来避免 NPE","link":"/2020/02/05/如何优雅的避免空指针/"},{"title":"基础同步工具类","text":"Semaphore，CountDownLatch，CyclicBarrier 均是 JDK1.5 提供的基础并发工具： Semaphore 是一个计数信号量，用于限制同时访问某个特定资源的数量 CountDownLatch 是一个闭锁，允许一个或多个线程等待一组其他线程执行完成后执行，但只能使用一次 CyclicBarrier 是一个循环栅栏，通过它可以实现让一组线程等待至某个状态之后再全部同时执行，并且支持重复使用 Semaphore123456789101112131415161718192021222324class X{ Random random = new Random(); Semaphore semaphore = new Semaphore(10, true); // 方法本身控制同步 public synchronized Integer getNextAvailableItem() throws InterruptedException { // 信号量控制访问次数 semaphore.acquire(); return random.nextInt(); } public synchronized boolean markAsUnused(Integer item){ // do something semaphore.release(); return true; }} 这是 Semaphore 的一个标准的使用方式，用于控制流量。上述程序创建了一个允许 10 个线程同时访问的信号量，并且使用公平锁（一般来说用于控制流量的使用需要使用公平模式，用于防止线程饥饿），然后在提供获取资源的接口 getNextAvailableItem 方法前先获取凭证，在释放资源后释放凭证。但是注意 Semaphore 不保证并发正确性，这需要接口自己保证，因此这里使用 synchronized 来提醒这一点。 简介Semaphore 默认使用非公平锁，也可以显示的设置使用公平锁 1234567public Semaphore(int permits) { sync = new NonfairSync(permits);}public Semaphore(int permits, boolean fair) { sync = fair ? new FairSync(permits) : new NonfairSync(permits);} 公平锁 FairSync 和非公平锁 NonfairSync 均继承于内部类 Sync，而 Sync 继承 AQS（AbstractQueuedSynchronizer）锁。获取锁和释放锁均在 Sycn 中实现 1234567891011public void acquire() throws InterruptedException { sync.acquireSharedInterruptibly(1);}public void acquireUninterruptibly() { sync.acquireShared(1);}public void release() { sync.releaseShared(1);} acquireacquire 在获取非公平锁的实现底层核心方法为 nonfairTryAcquireShared 123456789final int nonfairTryAcquireShared(int acquires) { for (;;) { int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; }} Semaphore 在初始化的时候会将 state 设为凭证数，在每次获取锁时 nonfairTryAcquireShared 会将 state - 1 直到 state 为 0，当 state 为 0 时则代表不可以再获取共享锁了。在具体实现上，这是一个标准的子类获取共享锁的实现模式。它本质是一个共享锁，会允许多个线程同时进入，因此在之前的使用介绍也提到了 Semaphore 不能确保并发正确性。 1234567891011protected int tryAcquireShared(int acquires) { for (;;) { if (hasQueuedPredecessors()) return -1; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; }} 而对于公平模式的获取锁和 ReentrantLock 的实现相同，会先调用 hasQueuedPredecessors 来判断当前线程是否位于等待队列中的第一个，仅在处于队列的第一个时才会尝试获取锁，从而保证了获取锁的先后顺序。 还需要注意的是，无论是公平锁还是非公平锁，Semaphore 的acquire 是调用的 acquireSharedInterruptibly，因此它是可中断的 123public void acquire() throws InterruptedException { sync.acquireSharedInterruptibly(1);} 如果需要使用不支持中断的，可以使用 acquireUninterruptibly 123public void acquireUninterruptibly() { sync.acquireShared(1);} release1234567891011121314public void release() { sync.releaseShared(1);}protected final boolean tryReleaseShared(int releases) { for (;;) { int current = getState(); int next = current + releases; if (next &lt; current) // overflow throw new Error(\"Maximum permit count exceeded\"); if (compareAndSetState(current, next)) return true; }} 实际上就是调用 AQS 的释放共享锁的方法，那么本质上尝试释放锁就是通过重载 tryReleaseShared 实现的。因为共享锁的释放锁是存在并发的，所以需要通过 CAS 自旋更新 state 状态，每次释放都会将 state + 1。这也是一个标准的子类释放共享锁的实现模式。因此我们也要警惕使用 release，因为它会导致当前 state 大于凭证数，意味着如果释放次数大于获取次数会导致同时允许的线程数大于凭证数。 &emsp;&emsp;There is no requirement that a thread that releases a permit must have acquired that permit by calling acquire(). Correct usage of a semaphore is established by programming convention in the application. &emsp;&emsp;没有要求释放许可证的线程必须先通过调用 acquire() 获得该许可证。通过应用程序中的编程约定来建立信号量的正确使用。 应用了解了 Semaphore 原理后，这里通过 Semaphore 实现一个线程池只能同时执行两个任务的例子 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485import java.util.concurrent.*;import java.util.concurrent.atomic.AtomicInteger;import java.util.concurrent.locks.ReentrantLock;public class Main { public static void main(String[] args) { final Semaphore semaphore = new Semaphore(2, true); AtomicInteger count = new AtomicInteger(0); ExecutorService executorService = new ThreadPoolExecutor( 5, 5, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(100), new ThreadPoolExecutor.DiscardOldestPolicy() ); int threadCnt = 10; for (int i = 0; i &lt; threadCnt; i++) { executorService.execute(new Task(semaphore, count)); } executorService.shutdown(); try { executorService.awaitTermination(1, TimeUnit.DAYS); } catch (InterruptedException e) { e.printStackTrace(); } }}class Task implements Runnable { private Semaphore semaphore; private AtomicInteger count; public Task(Semaphore semaphore, AtomicInteger count) { this.semaphore = semaphore; this.count = count; } @Override public void run() { try { semaphore.acquire(); } catch (InterruptedException e) { System.out.println(\"Semaphore 中断 \" + Thread.currentThread().getName()); return; } try { doIt(); } finally { semaphore.release(); } } private void doIt() { System.out.println(Thread.currentThread().getName() + \": is running [\" + count.addAndGet(1) + \"]\"); try { Thread.sleep((int)(1 + (Math.random() * 3))); } catch (InterruptedException e) { e.printStackTrace(); } finally { count.decrementAndGet(); } }} Task 任务会在执行前先获取信号量，并对同时在运行的任务进行计数，在执行完任务后会重置计数并释放信号量。在实现过程中需要注意两个重要的点，也是实际使用时需要注意的点： doIt 执行任务本身需要保证并发安全，所以 count 使用 Atomic 类。 Semaphore 的 acquire 和 release 不要在同一个 try 中，否则当 acquire 获取失败时仍然会执行 release，而 release并不控制凭证数，这会导致有可能产生比设置时更大的 state 在这个案例中，正常结果打印出来的同时运行的线程数不会超过 2，比如： 12345678910pool-1-thread-2: is running [2]pool-1-thread-1: is running [1]pool-1-thread-3: is running [2]pool-1-thread-4: is running [2]pool-1-thread-2: is running [1]pool-1-thread-5: is running [2]pool-1-thread-1: is running [2]pool-1-thread-3: is running [1]pool-1-thread-4: is running [2]pool-1-thread-5: is running [2] 重点回顾 Semaphore 底层通过 AQS 共享锁实现，支持公平/非公平模式 Semaphore 应用场景主要用于控制流量 Semaphore 并不保证并发正确性，需要接口本身保证 Semaphore 的 release 释放次数大于 acquire 获取次数时会导致并发数大于凭证数，因此这需要由调用者正确控制 CountDownLatch1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import java.util.concurrent.*;public class Main { public static void main(String[] args) { int threadCnt = 10; CountDownLatch startSignle = new CountDownLatch(1); CountDownLatch doneSignle = new CountDownLatch(threadCnt); ExecutorService executorService = new ThreadPoolExecutor( 5, 5, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(100), new ThreadPoolExecutor.DiscardOldestPolicy() ); for (int i = 0; i &lt; threadCnt; i++) { executorService.execute(new Task(startSignle, doneSignle)); } System.out.println(\"All task start.\"); startSignle.countDown(); try { doneSignle.await(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"All task done.\"); executorService.shutdown(); }}class Task implements Runnable { private CountDownLatch startSignle; private CountDownLatch doneSignle; public Task(CountDownLatch startSignle, CountDownLatch doneSignle) { this.startSignle = startSignle; this.doneSignle = doneSignle; } @Override public void run() { try { startSignle.await(); System.out.println(Thread.currentThread().getName() + \" is running\"); Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } finally { doneSignle.countDown(); } }} 上述程序创建了两个分别用于启动和结束的 CountDownLatch，startSignle 用于所有子线程等待主线程发送执行的信号，doneSignle 用于主线程等待所有子线程完成的信号。正常结果如下： 123456789101112All task start.pool-1-thread-2 is runningpool-1-thread-3 is runningpool-1-thread-4 is runningpool-1-thread-1 is runningpool-1-thread-5 is runningpool-1-thread-4 is runningpool-1-thread-1 is runningpool-1-thread-2 is runningpool-1-thread-5 is runningpool-1-thread-3 is runningAll task done. 简介CountDownLatch 的构造函数只有一个参数，用于控制 await 线程被执行前必须先执行线程的个数 1234public CountDownLatch(int count) { if (count &lt; 0) throw new IllegalArgumentException(\"count &lt; 0\"); this.sync = new Sync(count);} Sync 继承 AQS（AbstractQueuedSynchronizer）锁，因此 CountDownLatch 也是基于 AQS 的一个实现 1234567public void await() throws InterruptedException { sync.acquireSharedInterruptibly(1);}public void countDown() { sync.releaseShared(1);} await 调用的 acquireSharedInterruptibly 意味着它支持中断 await123protected int tryAcquireShared(int acquires) { return (getState() == 0) ? 1 : -1;} await 的获取共享锁的方式和之前所说的 Semaphore 的实现对 state 的处理是完全相反的： 在 Semaphore 中是在 state 大于 0 时允许获取锁 在 CountDownLatch 中是在 state = 0 时允许获取锁 这很好理解，await 的线程需要在 N 个线程执行 countDown 后才允许被唤醒，和 Semaphore 的逻辑正好相反。 countDown1234567891011protected boolean tryReleaseShared(int releases) { // Decrement count; signal when transition to zero for (;;) { int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; }} countDown 本质上就是释放共享锁，每次执行会将 state - 1 直到 0。在释放到 state = 0 后不会再释放。这就说明了两个问题： 即使执行 countDown 的次数大于初始化时设置的 count 值也是不会有问题的，因为 releaseShared 会直接返回释放失败。 即使先执行 countDown，只要执行到足够的次数，再执行 await 也能成功获取到锁。 &emsp;&emsp;为什么 await 方法获取锁成功是返回 1，而不是 0 呢？ &emsp;&emsp;这是因为在 AQS 中，释放共享锁后会唤醒后继结点，而后续的唤醒则依赖于获取锁的线程的传播式向后唤醒结点，而这依赖于 tryAcquireShared 的返回结果，当返回 0 时会被 AQS 认为无剩余共享资源导致无法唤醒后续结点。那么这就会导致最后一个 countDown 执行完后无法唤醒所有由 await 阻塞的线程 最后那么我们来模拟多个线程等待多个线程执行完成后唤醒的过程：假设 A, B 两个线程等待 m, n 线程执行完成才能执行，而 A, B 先于 m, n 执行 A 线程调用 await，因为 state 为 2 进入 AQS 等待队列，为头结点 B 线程调用 await，因为 state 为 2 进入 AQS 等待队列，插入队尾 m 线程调用 countDown，将 state 设为 1，释放锁成功，尝试唤醒 A，A 尝试获取锁但因为 state != 0，唤醒失败 n 线程调用 countDown，将 state 设为 0，释放锁成功，尝试唤醒 A，A 尝试获取锁因为 state = 0，A 唤醒成功 A 获取锁成功返回 1 允许传播式尝试唤醒 B，B 尝试获取锁因为 state = 0，B 唤醒成功 重点回顾 CountDownLatch 底层通过 AQS 共享锁实现 CountDownLatch 的应用场景为一个或多个线程等待一组其他线程执行完成后执行 CountDownLatch 的 countDown 次数大于初始化时设置的 count 值时会抛出异常 CountDownLatch 的 countDown 方法可以先于 await 方法先执行 CyclicBarrier123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081import java.util.concurrent.*;import java.util.concurrent.atomic.AtomicInteger;public class Main { public static void main(String[] args) { int threadCnt = 5; CyclicBarrier cyclicBarrier = new CyclicBarrier(threadCnt); AtomicInteger count = new AtomicInteger(0); ExecutorService executorService = new ThreadPoolExecutor( 5, 10, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(100), new ThreadPoolExecutor.DiscardOldestPolicy() ); for (int i = 0; i &lt; threadCnt; i++) { executorService.execute(new Task(cyclicBarrier, threadCnt * 2, count)); } executorService.shutdown(); try { executorService.awaitTermination(1, TimeUnit.DAYS); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"All tasks done.\"); }}class Task implements Runnable { private CyclicBarrier cyclicBarrier; private AtomicInteger count; private Integer taskCnt; public Task(CyclicBarrier cyclicBarrier, Integer taskCnt, AtomicInteger count) { this.cyclicBarrier = cyclicBarrier; this.taskCnt = taskCnt; this.count = count; } @Override public void run() { try { while (!isDone()){ System.out.println(Thread.currentThread().getName() + \" starts.\"); Thread.sleep(2000); count.addAndGet(1); System.out.println(Thread.currentThread().getName() + \" is waiting.\"); cyclicBarrier.await(); } System.out.println(Thread.currentThread().getName() + \" quit.\"); } catch (InterruptedException | BrokenBarrierException e) { e.printStackTrace(); } } private boolean isDone(){ return taskCnt.equals(count.get()); }} 上述程序创建了一个需要 5 个线程到达后每个线程才能执行后续流程的循环栅栏 CyclicBarrier。每个任务执行完毕后会将 count + 1 以及通过 await 等待其他线程完成。而每个线程完成所有任务的标志是 count = 10，因此在前 5 个执行完成后又会重复的执行一轮，最后全部线程退出。正常结果如下： 1234567891011121314151617181920212223242526pool-1-thread-2 starts.pool-1-thread-5 starts.pool-1-thread-4 starts.pool-1-thread-3 starts.pool-1-thread-1 starts.pool-1-thread-5 is waiting.pool-1-thread-4 is waiting.pool-1-thread-3 is waiting.pool-1-thread-1 is waiting.pool-1-thread-2 is waiting.pool-1-thread-2 starts.pool-1-thread-5 starts.pool-1-thread-4 starts.pool-1-thread-3 starts.pool-1-thread-1 starts.pool-1-thread-4 is waiting.pool-1-thread-1 is waiting.pool-1-thread-5 is waiting.pool-1-thread-3 is waiting.pool-1-thread-2 is waiting.pool-1-thread-2 quit.pool-1-thread-4 quit.pool-1-thread-3 quit.pool-1-thread-1 quit.pool-1-thread-5 quit.All tasks done. &emsp;&emsp;CyclicBarrier 结合线程池使用需要注意死锁问题，当线程池可执行线程数小于 CyclicBarrier 触发栅栏的线程时会产生死锁 简介CyclicBarrier 存在两个构造函数，parties 用于执行在触发栅栏之前需要执行的线程数，barrierAction 为触发栅栏的线程首先执行该任务后才会唤醒所有等待的线程 12345678910public CyclicBarrier(int parties, Runnable barrierAction) { if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction;}public CyclicBarrier(int parties) { this(parties, null);} await123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public int await() throws InterruptedException, BrokenBarrierException { try { return dowait(false, 0L); } catch (TimeoutException toe) { throw new Error(toe); // cannot happen }}private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException { final ReentrantLock lock = this.lock; lock.lock(); try { // 当前代 final Generation g = generation; if (g.broken) throw new BrokenBarrierException(); if (Thread.interrupted()) { breakBarrier(); throw new InterruptedException(); } int index = --count; // 当index=0时代表触发栅栏 if (index == 0) { // tripped boolean ranAction = false; try { // 首先执行传入的任务 final Runnable command = barrierCommand; if (command != null) command.run(); ranAction = true; // 然后更新代，唤醒所有等待线程 nextGeneration(); return 0; } finally { if (!ranAction) breakBarrier(); } } // 如果还没触发栅栏，则阻塞 // loop until tripped, broken, interrupted, or timed out for (;;) { try { // 如果未设置超时时间，则直接阻塞 if (!timed) trip.await(); // 否则对阻塞设置超时时间 else if (nanos &gt; 0L) nanos = trip.awaitNanos(nanos); } catch (InterruptedException ie) { if (g == generation &amp;&amp; ! g.broken) { breakBarrier(); throw ie; } else { // We're about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // \"belong\" to subsequent execution. Thread.currentThread().interrupt(); } } if (g.broken) throw new BrokenBarrierException(); if (g != generation) return index; if (timed &amp;&amp; nanos &lt;= 0L) { breakBarrier(); throw new TimeoutException(); } } } finally { lock.unlock(); }} CyclicBarrier 是一个可以循环使用的栅栏，因此它有一个“代”的概念，即每个在触发栅栏之前需要执行的线程数为一代，每执行一次任务则会将需要执行的线程数减一直到 0，这时候就进入了新的一代，即新的循环。 await 实际上通过 ReentrantLock + Condition 完成线程的阻塞和唤醒： 判断当前线程在当前代中的位置，如果还不能触发栅栏，则调用 condition.await/awaitNanos 对当前线程进行阻塞 如果一个线程触发了栅栏，首先执行传入的 Runnable 任务，然后唤醒所有等待的任务，再更新代 每个被唤醒的线程检查当前代是否已经更新，如果已经更新，则返回在阻塞时还剩余需要执行的线程数。因此 barrier.await() == 0 时意味着当前代需要执行的最后一个线程已完成，可以做些一轮任务做完需要做的工作，比如整合，日志等 123if (barrier.await() == 0) { // log the completion of this iteration} 但是它和 barrierAction 还是有些区别，barrierAction 中执行的内容会在唤醒其他线程前执行（新代执行前），而 barrier.await() == 0 内执行的内容则是在唤醒其他线程后执行的（有可能新代已经开始执行），因此在使用时需要多加考虑 &emsp;&emsp;CountDownLatch 和 CyclicBarrier 比较相似，都是多个线程相互等待后执行，但它们还是有比较大的区别： 从实现来看，CountDownLatch 使用的是共享锁，所以一次 countDown 能唤醒所有 await 等待的线程；而 CyclicBarrier 使用的互斥锁 + Condition 的方式，由调用 await 触发栅栏的线程来唤醒一个代中的所有线程（signAll） 从功能来看，CountDownLatch 只允许使用一次，而 CyclicBarrier 允许循环使用 从应用来看，CountDownLatch 适用于一个或多个线程等待一组线程执行完成后执行，比如初始化；而 CyclicBarrier 适合用于一组线程相互之间等待，达到一个共同点，再继续执行。比如并行计算，计算中涉及多个子任务阶段式完成任务","link":"/2019/02/11/基础同步工具类/"},{"title":"泛型进阶","text":"无限制通配符无限通配符即： &lt;?&gt;，主要在不确定或不关心实际参数类型时使用，如： 123public boolean removeAll(Collection&lt;?&gt; c){ ...} 由于它不确定具体类型，所以不能将任何元素（Null 除外）放入，即它是只读的，但在很多情况下需要放入对象，因此一种比较常见的方法是使用 类型参数 作为辅助函数 1234567public static void swap(List&lt;?&gt; list, int i, int j){ swapHelper(list, i, j);}public static &lt;E&gt; void swapHelper(List&lt;E&gt; list, int i, int j){ list.set(i, list.get(j));} 那么 List&lt;?&gt; 和 List&lt;Object&gt; 有什么区别呢？ List&lt;Object&gt; 已经指定了类型的参数，而泛型具有不变性，所以它只能传入参数类型为 Object 123456test(new ArrayList&lt;Object&gt;()); // 正确test(new ArrayList&lt;String&gt;()); // 错误void test(List&lt;Object&gt; list){ System.out.println(list);} 而 List&lt;?&gt; 是无限制通配符类型，它可以表示为任意的实际的类型参数 123456test(new ArrayList&lt;Object&gt;()); // 正确test(new ArrayList&lt;String&gt;()); // 正确void test(List&lt;?&gt; list){ System.out.println(list);} List&lt;Object&gt; 的类型参数已经确定，所以可以对其中的元素进行诸如 get , add 、remove 等操作 12345void test(List&lt;Object&gt; list){ list.add(\"str\"); list.add(1); list.remove(\"str\");} 而 List&lt;?&gt; 是只读的，不能 add ，只能 get , remove 操作（当然可以使用上述的辅助函数实现 add），且返回元素都是 Object 类型的 1234void test(List&lt;?&gt; list){ list.get(0); list.remove(\"str\");} 所以一般情况下，使用无限制通配符的优先级大于 Object 作为类型参数 有限制通配符java 泛型有两种有限制通配符，&lt;? extends E&gt; 和 &lt;? super E&gt;，那么它们的作用是什么呢？这要从协变和逆变说起。 协变（Covariance）和逆变（Contravariance）逆变与协变用来描述类型转换（type transformation）后的继承关系 协变：具有子类型关系之间的类型经过“类型转换”后，所构造出更复杂的类型之间仍保持着子类型关系。 逆变：具有子类型关系之间的类型经过“类型转换”后，所构造的更复杂的类型之间建立了逆向子类型关系。 不变：具有子类型关系之间的类型经过“类型转换”后，所构造的更复杂的类型之间没有任何关系 这里指的类型转换代表指的是从一种类型构造为另一种新的类型，如 String 到 String[]，String 到 List&lt;String&gt;。在 java 中，泛型具有不变性，如 1234Number number = new Integer(0); // TrueArrayList&lt;Number&gt; arrayList = new ArrayList&lt;Number&gt;(); // TrueArrayList&lt;Number&gt; arrayList1 = new ArrayList&lt;Integer&gt;(); // 编译错误ArrayList&lt;Number&gt; arrayList1 = new ArrayList&lt;Object&gt;(); // 编译错误 那么问题的答案就出现了：有限制通配符是为了实现泛型的协变与逆变 &lt;? extends E&gt; 实现了泛型的协变： 1ArrayList&lt;? extends Number&gt; arrayList = new ArrayList&lt;Integer&gt;(); &lt;? super E&gt; 实现了泛型的逆变： 1ArrayList&lt;? super Number&gt; arrayList = new ArrayList&lt;Object&gt;(); extends 与 super有限制通配符有它的局限性，看一个例子： 12List&lt;? extends Number&gt; list = new ArrayList&lt;Integer&gt;();list.add(new Integer(1)); 我们通过 extends 通配符构建了对象，但是却不能插入 Integer 类型的元素，这看起来很不合理。其实这是可以理解的，首先看一些 List 类的 add 方法接口 123public interface List&lt;E&gt; extends Collection&lt;E&gt; { boolean add(E e);} 在调用 add 方法时，泛型 E 自动变成了 &lt;? extends Number&gt;，也就是说其类型是 Number 的子类中的一个（不含 Number），因此 add 一个 Integer 类型对象是错误的。如果要实现 add 一个 Interger 对象，可以使用 super 关键字 12List&lt;? super Number&gt; list = new ArrayList&lt;Object&gt;();list.add(new Integer(1)); &lt;? super Number&gt; 代表其持有的类型是 Number 的父类，那么 add 一个 Integer 类型对象是正确的。所以我们又可以总结出： &lt;? extends Number&gt; 是只读的 &lt;? super Number&gt; 是只写的 应用那么究竟什么时候用 extends，什么时候用 super 呢？其实很简单，遵循 PECS 原则 PECS: producer-extends, consumer-super. 换句话说： 如果要从泛型类取数据时，用 extends 如果要往泛型类写数据时，用 super 举几个例子，首先看 java.util.AbstractList 的 addAll 方法 123456789public boolean addAll(int index, Collection&lt;? extends E&gt; c) { rangeCheckForAdd(index); boolean modified = false; for (E e : c) { // 注意这里，从泛型类中获取对象!! add(index++, e); modified = true; } return modified;} addAll 方法需要将传入的泛型类中的所有元素保存到当前集合中，因此将从泛型类读取所有元素，所以使用 extends。又如 java.util.Collections 的 copy 方法 123456789101112131415161718public static &lt;T&gt; void copy(List&lt;? super T&gt; dest, List&lt;? extends T&gt; src) { int srcSize = src.size(); if (srcSize &gt; dest.size()) throw new IndexOutOfBoundsException(\"Source does not fit in dest\"); if (srcSize &lt; COPY_THRESHOLD || (src instanceof RandomAccess &amp;&amp; dest instanceof RandomAccess)) { for (int i=0; i&lt;srcSize; i++) dest.set(i, src.get(i)); // 从src泛型类读取数据，写入dest泛型类！！！ } else { ListIterator&lt;? super T&gt; di=dest.listIterator(); ListIterator&lt;? extends T&gt; si=src.listIterator(); for (int i=0; i&lt;srcSize; i++) { di.next(); di.set(si.next()); } }} copy 方法将一个集合中的元素拷贝到另一个集合，完美的诠释了有限制通配符的使用。 拓展考虑以下代码： 123456789public static &lt;T extends Comparable&lt;T&gt;&gt; T max(Collection&lt;T&gt; coll){ T max = coll.iterator().next(); for (T elm : coll) { if (max.compareTo(elm) &lt; 0) max = elm; } return max;} 它的作用是对集合中的元素进行排序，那么我们需要对传入的集合中的元素进行限定，它需要能够进行比较，即实现 Comparable 接口，&lt;T extends Comparable&lt;T&gt;&gt; 的作用就是如此。但在继承关系中，上述声明会出现错误，考虑以下情况： 12345678910111213141516171819202122232425class Fruit implements Comparable&lt;Fruit&gt; { private String name; private int size; public Fruit(String name, int size) { this.name = name; this.size = size; } @Override public int compareTo(Fruit that) { if (size &lt; that.size) return -1; else if (size == that.size) return 0; else return 1; }}class Apple extends Fruit { public Apple(int size) { super(\"Apple\", size); }} Apple 类继承了 Fruit 类，但是它没有实现 Comparable&lt;Apple&gt;，而是实现了 Comparable&lt;Fruit&gt;，因此它不符合 &lt;T extends Comparable&lt;T&gt;&gt; 要求，因此不能对 Apple 集合使用 12345List&lt;Apple&gt; list = new ArrayList&lt;&gt;();list.add(new Apple(10));list.add(new Apple(20));Algorithm.&lt;Apple&gt;max(list); // 编译错误 因此，为了能够对这种情况予以支持，需要使用如下声明： 1public static &lt;T extends Comparable&lt;? super T&gt;&gt; T max(Collection&lt;T&gt; coll) &lt;T extends Comparable&lt;? super T&gt;&gt;的限定含义是： T implements Comparable&lt;T&gt; T implements Comparable&lt;X&gt;，其中 X 是 T 的父类 其实以之前的 PECS 原则也能很好的解释，无论是 Comparable 还是 Comparator，它们的方法都需要写数据，即向泛型类写数据，所以需要使用 &lt;? super T&gt; ，所以使用 Comparator 的声明为： 1public static &lt;T&gt; T max(Collection&lt;T&gt; coll, Comparator&lt;? super T&gt; c) 其实到这里为止，这个 API 已经能够支持大部分情况了。但是假设我们需要传入的泛型集合是 T 的子类，将会仍然编译错误 1Algorithm.&lt;Fruit&gt;max(list); // T为Fruit，传入的是List&lt;Apple&gt;，编译错误 这就是之前说的泛型的不变性问题，因此，最灵活的声明是： 1public static &lt;T extends Comparable&lt;? super T&gt;&gt; T max(Collection&lt;? extends T&gt; coll) 也许你不太明白我们这样使用它的意义，为什么一定要强制加一个 &lt;Fruit&gt; 呢？看起来没什么必要，其实这是在模拟一种情况，上述的声明等同于如下： 123456789101112class Algorithm&lt;T extends Comparable&lt;? super T&gt;&gt;{ public T max(Collection&lt;? extends T&gt; coll) { T max = coll.iterator().next(); for (T elm : coll) { if (max.compareTo(elm) &lt; 0) max = elm; } return max; }} 这样的调用是不是就比较常见了 123456List&lt;Apple&gt; list = new ArrayList&lt;&gt;();list.add(new Apple(10));list.add(new Apple(20));Algorithm&lt;Fruit&gt; fruitAlgorithm = new Algorithm&lt;&gt;();fruitAlgorithm.max(list); 其实 java.util.Collections 的 max 方法可以看到类似的声明： 1234567891011public static &lt;T extends Object &amp; Comparable&lt;? super T&gt;&gt; T max(Collection&lt;? extends T&gt; coll) { Iterator&lt;? extends T&gt; i = coll.iterator(); T candidate = i.next(); while (i.hasNext()) { T next = i.next(); if (next.compareTo(candidate) &gt; 0) candidate = next; } return candidate;} 其中使用 Object &amp; 主要是因为泛型擦除，编译生成的 Java 字节码中是不包含泛型中的类型信息，泛型类型会被 Object 所代替（无限制通配符也用 Object），而有限制通配符则会被第一个边界的类型变量来替换，如上面的声明会被 Comparable 所代替，使用了 Object &amp; 后将被 Object 所代替，参看 Why is T bounded by Object in the Collections.max() signature? 泛型单例类实现一个泛型单例类，使得它能够对于传入任意类型的 Class 对象都创建一个单例对象 1234567891011121314151617181920212223242526public class Singleton { private final static Map&lt;Class&lt;?&gt;, Object&gt; INSTANCE_MAP = new HashMap&lt;&gt;(); public static &lt;T&gt; T getInstance(Class&lt;T&gt; tClass){ Object instance = INSTANCE_MAP.get(tClass); if(instance == null){ synchronized (INSTANCE_MAP){ if(instance == null){ try { instance = tClass.newInstance(); INSTANCE_MAP.put(tClass, instance); } catch (InstantiationException | IllegalAccessException e) { e.printStackTrace(); } } } } // Class的cast方法能够动态的将Object类型转换为Class对象所表示的类型，如果能转就返回，不能转就抛出类型转换失败异常 // 这样就不需要借助于未受检警告（(T)instance） return tClass.cast(instance); }} 创建 Persion 类 12345678910111213141516171819202122public class Person { /** * 姓名 */ String name; /** * 身份证 */ String idcard; /** * 年龄 */ Integer age; /** * 电子邮件 */ String email;} 将它传入泛型单例类，每次 getInstance 可以得到相同的对象 1System.out.println(Singleton.getInstance(Person.class) == Singleton.getInstance(Person.class)); // True 最佳实践1. 不应使用原生态类型原生态类型即不带实际类型参数的泛型名称，如 List&lt;E&gt; 的原生态类型为 List。它逃避了泛型检查，当你不小心插入了类型错误的对象，在运行时转换对象会出现 ClassCastException 。因此应该摈弃这样的做法，取而代之使用泛型，优点有以下两点： 在编译期间进行类型检查 获取对象不需要手动转换类型 例子如下： 1234567891011121314151617// 原生态类型，不推荐ArrayList list = new ArrayList();list.add(\"str\");list.add(1);for (Object o : list) { String s = (String)o; // 抛出ClassCastException}// 泛型，推荐ArrayList&lt;String&gt; list = new ArrayList();list.add(\"str\");list.add(1); // 1. 编译期检查错误，不允许添加整形for (String o : list) { String s = o; // 2. 不需手动转换类型} 2. 不要使用通配符类型作为返回类型使用通配符类型作为返回类型将会强制在客户端代码中使用通配符类型，如： 12345678// 使用通配符类型作为返回类型，不推荐public void use(){ List&lt;?&gt; list = returnGenericsType();}public List&lt;?&gt; returnGenericsType(){ return new ArrayList&lt;&gt;();} 3. 泛型无法使用instanceof由于泛型擦除，编译期间会擦除类型参数，所以不能使用 instanceof 1234List&lt;Apple&gt; list = new ArrayList&lt;&gt;();if(list instanceof List&lt;Apple&gt;){ // 错误 ...} 而对于无限制通配符是可以使用 instanceof 的 1234List&lt;?&gt; list = new ArrayList&lt;&gt;();if(list instanceof List&lt;?&gt;){ // 错误 ...} 当然尖括号和 ? 有些多余，可以直接判断 1list instanceof List","link":"/2019/12/06/泛型进阶/"},{"title":"揭开try-catch-finally的神秘面纱","text":"根据 JDK Tutorial 的描述，除非在执行 try 或 catch 代码时线程被中断或 JVM 退出，finally 中的逻辑始终会执行。因此 finally 关键字常被用于释放资源，防止程序出现异常时出现资源泄露。本文主要探讨其在 JVM 层面的实现原理，以及 synchronized 关键字在类似场景的处理手段。首先来看一段简单的 try-finally 代码 1234567public void testWithTryFinally() { try { System.out.println(\"try\"); } finally { System.out.println(\"finally\"); }} 其对应字节码如下 123456789101112131415161718stack=2, locals=2, args_size=1 0: getstatic #5 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #6 // String try 5: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: getstatic #5 // Field java/lang/System.out:Ljava/io/PrintStream; 11: ldc #8 // String finally 13: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 16: goto 30 19: astore_1 20: getstatic #5 // Field java/lang/System.out:Ljava/io/PrintStream; 23: ldc #8 // String finally 25: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 28: aload_1 29: athrow 30: returnException table: from to target type 0 8 19 any 其中： 0 - 8 行是 try 中的语句 8 - 13，20 - 25 行是 finally 中的语句 那么为什么 finally 语句会出现两遍呢？其实这两次分别对应程序正常执行和异常执行的情况，8 - 13 行是在正常执行时会执行的 finally 语句，执行完成后通过 16 行的 goto 指令跳转到 return 指令返回；而 20 - 25 行则是由异常表（Exception table）进行触发，可以看到异常表会捕捉 0 - 8 行（不包含第8行）的字节码出现的任意异常，并且跳转至 19 行开始执行 finally 语句，最后通过 29 行 athrow 指令向上抛出异常。 那么如果增加 catch 呢，会有什么区别吗？ 123456789public void testWithTryCatchFinally() { try { System.out.println(\"try\"); } catch (Exception e) { System.out.println(\"catch\"); } finally { System.out.println(\"finally\"); } } 其字节码如下： 12345678910111213141516171819202122232425262728stack=2, locals=3, args_size=1 0: getstatic #5 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #6 // String try 5: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: getstatic #5 // Field java/lang/System.out:Ljava/io/PrintStream; 11: ldc #8 // String finally 13: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 16: goto 50 19: astore_1 20: getstatic #5 // Field java/lang/System.out:Ljava/io/PrintStream; 23: ldc #10 // String catch 25: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 28: getstatic #5 // Field java/lang/System.out:Ljava/io/PrintStream; 31: ldc #8 // String finally 33: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 36: goto 50 39: astore_2 40: getstatic #5 // Field java/lang/System.out:Ljava/io/PrintStream; 43: ldc #8 // String finally 45: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 48: aload_2 49: athrow 50: return Exception table: from to target type 0 8 19 Class java/lang/Exception 0 8 39 any 19 28 39 any 0 - 5 行是 try 中的语句 20 - 25 行是 catch 中的语句 8 - 13, 28 - 33, 40 - 45 行是 finally 中的语句 大体上和之前逻辑相同，只不过这里 finally 中的语句又赋予了 catch 一遍，所以被 catch 后也能执行 finally 语句。根据上面两个例子，我们也验证了 JDK Tutorial 的描述，即除非在执行 try 或 catch 代码时线程被中断或 JVM 退出，finally 中的逻辑始终会执行。 包含控制语句的 try-finally不知道大家有没有注意到，finally 语句的字节码前后总会出现 astore/aload 这样成对的指令，它们的作用是什么呢？根据指令本身的含义，我们可以知道 astore 是将操作数栈顶存储到局部变量表 aload 是将局部变量加载到操作数栈，以便后续 ireturn 指令将栈顶的值返回给方法调用者 它在我们分析包含控制转移语句（比如 return）的 try-catch-finally 有着至关重要的作用。举一个包含控制语句的 try-finally 的例子 12345678910public int testWithTryReturnFinally() { int i = 0; try { return i; } finally { i++; }}# output: 0 其字节码如下： 123456789101112131415stack=1, locals=4, args_size=1 0: iconst_0 1: istore_1 2: iload_1 3: istore_2 4: iinc 1, 1 7: iload_2 8: ireturn 9: astore_3 10: iinc 1, 1 13: aload_3 14: athrow Exception table: from to target type 2 4 9 any 0：将常量 0 加载到操作数栈 1：将栈顶 int 数值存入第 2 局部变量（其中由于这里是方法调用，第 1 局部变量被调用方执行 invokevirtual 指令将对象的引用隐式的传进来了），此时第 2 局部变量的值为 0 2：将第 2 局部变量（0）的值加载到操作数栈 3：将栈顶的值存入第 3 局部变量（这里开始了 finally 的逻辑），这里相当于对 try 中的结果做了一次备份，此时第 3 局部变量的值为 0 4：将第 2 局部变量（0）的值加 1 7：加载第 3 局部变量的值到操作数栈（finally 语句结束），这里取出的是之前备份的值 8：返回栈顶元素，此时由于栈顶是执行 finally 前备份的值，所以值为 0 9：将栈顶的异常对象存入第 4 局部变量（进入到该阶段的指令一般由异常表触发，所以此时栈顶是异常对象） 10：将第 2 局部变量（0）的值加 1 13：将第 4 局部变量（异常对象）加载到操作数栈 14：将栈顶（异常对象）抛出 上述解释将对于最终返回结果比较重要的 3 和 7 指令进行了加粗，它展示了虽然 finally 语句会执行，但是它的计算结果不一定会影响到返回值，所以这里是容易被误解的地方，平常要避免这样使用。 那么是不是说放在 finally 中的计算都不会影响到 return 的结果呢？那当然不是，比如 return 不在 try 中，那么自然是会影响的，而如果 return 如果在 finally 中，又是什么样一种结果呢？比如： 1234567891011public int testWithTryReturnFinally() { int i = 0; try { return i; } finally { i++; return i; }}# output: 1 其字节码如下： 123456789101112131415stack=1, locals=4, args_size=1 0: iconst_0 1: istore_1 2: iload_1 3: istore_2 4: iinc 1, 1 7: iload_1 8: ireturn 9: astore_3 10: iinc 1, 1 13: iload_1 14: ireturn Exception table: from to target type 2 4 9 any 看 7 和 13 指令，这里和刚才的有比较大的区别，它们用于返回的 iload_1 是原本的值（非备份），因此返回的结果是 1。当然还有一个更重要的区别是：在 finally 中使用了 return 后丢失了 athrow，这意味着 try 中抛出的异常会丢失（finally 中抛出的异常仍然会继续抛出），这是一个比较严重的问题。这里使用一个例子演示一下： 1234567891011121314public int testWithTryReturnFinallyException() { int i = 0; try { if(true) { throw new RuntimeException(); } return i; } finally { i++; return i; }}# output: 1 上述代码并不会抛出异常，而是返回 1。所以 finally 中要避免使用 return，否则会得到意想不到的结果。经过上述几个例子，现在对 try-catch-finally 做了一个总结： 除非在执行 try 或 catch 代码时线程被中断或 JVM 退出，否则 finally 中的逻辑始终会执行 finally 语句块会在 try block 的控制转移语句（如 return）之前执行，但不会影响最终返回的结果，除非 finally 抛出了异常或使用了 return 等控制转移语句 避免在 finally 中使用 return，这会导致 try block 中的异常被丢失 synchronized 如何保证始终执行 monitorexit我们都知道 synchronized 对于同步语句块会使用 monitorenter 和 monitorexit 字节码指令，那么它们如何保证退出时始终执行 monitorexit 呢？答案其实和 finally 类似，我们举个例子： 12345public void testWithSync() { synchronized (this) { System.out.println(\"sync\"); }} 其字节码如下： 123456789101112131415161718192021stack=2, locals=3, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter 4: getstatic #5 // Field java/lang/System.out:Ljava/io/PrintStream; 7: ldc #6 // String sync 9: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 12: aload_1 13: monitorexit 14: goto 22 17: astore_2 18: aload_1 19: monitorexit 20: aload_2 21: athrow 22: return Exception table: from to target type 4 14 17 any 17 20 17 any 根据异常表可知即使同步块内容出现异常（4 - 14），仍然会跳转至 17 完成 monitorexit 的执行，这不就是 finally 的执行过程吗。但是这里相对 finally 有一个特殊的地方就是异常表对 17 - 20 行出现异常的情况进行了无限循环，而 17 - 20 行实际上就是执行 monitorexit 的过程，也就是说一旦 monitorexit 抛出异常，那么线程就会进入无限循环。根据 The Java Virtual Machine Instruction Set 介绍，monitorexit 会存在抛出 NullPointerException 和 IllegalMonitorStateException 两种异常，这就证明确实会存在无限循环的可能性。 If objectref is null, monitorexit throws a NullPointerException. Otherwise, if the thread that executes monitorexit is not the owner of the monitor associated with the instance referenced by objectref, monitorexit throws an IllegalMonitorStateException. Otherwise, if the Java Virtual Machine implementation enforces the rules on structured locking described in §2.11.10 and if the second of those rules is violated by the execution of this monitorexit instruction, then monitorexit throws an IllegalMonitorStateException. 那么这合理吗？在 2002 年就有一个 Bug 描述 JDK-4414101 : synchronized statement generates catch around the monitorexit 被提交，但最终被标记为非 bug。回答者认为无限循环是一个正确的行为，因为同步代码块的退出始终需要伴随着 monitor 的释放，一旦做不到这一点那么将线程放入无限循环中比执行其他操作更正确","link":"/2020/05/17/揭开try-catch-finally的神秘面纱/"}],"tags":[{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"锁","slug":"锁","link":"/tags/锁/"},{"name":"多线程","slug":"多线程","link":"/tags/多线程/"},{"name":"DNS","slug":"DNS","link":"/tags/DNS/"},{"name":"UDP","slug":"UDP","link":"/tags/UDP/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"故障排查","slug":"故障排查","link":"/tags/故障排查/"},{"name":"HTTP","slug":"HTTP","link":"/tags/HTTP/"},{"name":"Mysql","slug":"Mysql","link":"/tags/Mysql/"},{"name":"Reactor","slug":"Reactor","link":"/tags/Reactor/"},{"name":"NIO","slug":"NIO","link":"/tags/NIO/"},{"name":"最佳实践","slug":"最佳实践","link":"/tags/最佳实践/"},{"name":"可见性","slug":"可见性","link":"/tags/可见性/"},{"name":"内存屏障","slug":"内存屏障","link":"/tags/内存屏障/"},{"name":"操作系统","slug":"操作系统","link":"/tags/操作系统/"},{"name":"volatile","slug":"volatile","link":"/tags/volatile/"},{"name":"泛型","slug":"泛型","link":"/tags/泛型/"}],"categories":[{"name":"JUC","slug":"JUC","link":"/categories/JUC/"},{"name":"计算机通信","slug":"计算机通信","link":"/categories/计算机通信/"},{"name":"JVM","slug":"JVM","link":"/categories/JVM/"},{"name":"Mysql","slug":"Mysql","link":"/categories/Mysql/"},{"name":"Netty","slug":"Netty","link":"/categories/Netty/"},{"name":"Java基础","slug":"Java基础","link":"/categories/Java基础/"},{"name":"Tomcat","slug":"Tomcat","link":"/categories/Tomcat/"}]}